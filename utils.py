"""
å·¥å…·å‡½æ•°æ¨¡å—
åŒ…å«å„ç§è¾…åŠ©åŠŸèƒ½
"""

import torch
import os
import random
from typing import Dict
import numpy as np
import scipy.io
import h5py

def set_seed(seed: int) -> None:
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = False

def pre_load_mat_data(file_path: str) -> Dict[str, np.ndarray]:
    """åŠ è½½MATæ–‡ä»¶æ•°æ®ï¼Œè¿”å›åŒ…å«æ‰€æœ‰å­—æ®µçš„å­—å…¸"""
    try:
        # å°è¯•ä½¿ç”¨scipy.ioåŠ è½½
        mat_data = scipy.io.loadmat(file_path)
        
        # è¿‡æ»¤æ‰MATLABå…ƒæ•°æ®å­—æ®µ
        filtered_data = {}
        for key, value in mat_data.items():
            if not key.startswith('__') and isinstance(value, np.ndarray):
                filtered_data[key] = value
        
        if filtered_data:
            return filtered_data
        else:
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®å­—æ®µ")
                
    except Exception as e:
        if "HDF reader" in str(e): 
            # ä½¿ç”¨h5pyåŠ è½½v7.3æ ¼å¼
            with h5py.File(file_path, 'r') as f:
                filtered_data = {}
                def collect_data(name, obj):
                    if isinstance(obj, h5py.Dataset):
                        filtered_data[name] = np.array(obj)
                
                f.visititems(collect_data)
                
                if filtered_data:
                    return filtered_data
                else:
                    raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®å­—æ®µ")
        else:
            raise e
    
    raise ValueError(f"æ— æ³•åŠ è½½MATæ–‡ä»¶: {file_path}")

def load_mat_data(file_path: str, lazy: bool = True):
    """
    å®‰å…¨åŠ è½½å¤§å‹ .mat æ–‡ä»¶ï¼ˆæ”¯æŒ v7.3ï¼‰

    Args:
        file_path (str): .mat æ–‡ä»¶è·¯å¾„
        lazy (bool): æ˜¯å¦é‡‡ç”¨æ‡’åŠ è½½ï¼ˆTrue æ¨èï¼Œç”¨äºå¤§æ–‡ä»¶ï¼‰

    Returns:
        dict[str, np.ndarray or h5py.Dataset]: é”®åâ†’æ•°æ®
    """
    try:
        # â‘  ä¼˜å…ˆå°è¯•å¸¸è§„ .matï¼ˆé€‚åˆ <2GBï¼‰
        mat_data = scipy.io.loadmat(file_path)
        filtered_data = {
            k: v for k, v in mat_data.items()
            if not k.startswith('__') and isinstance(v, np.ndarray)
        }
        if filtered_data:
            print(f"âœ… ä½¿ç”¨ scipy.io.loadmat() æˆåŠŸåŠ è½½: {file_path}")
            return filtered_data

    except Exception as e:
        # â‘¡ è‹¥æ–‡ä»¶ä¸º v7.3ï¼ˆåŸºäº HDF5ï¼‰ï¼Œæ”¹ç”¨ h5py
        if "HDF" in str(e) or "mat file appears to be HDF5" in str(e):
            print(f"ğŸ” æ£€æµ‹åˆ°å¤§å‹ v7.3 æ–‡ä»¶ï¼Œä½¿ç”¨ h5py åŠ è½½: {file_path}")
        else:
            print(f"âš ï¸ loadmat å¤±è´¥ï¼Œè‡ªåŠ¨å°è¯• h5py: {e}")

    # === ä½¿ç”¨ h5py è¯»å– v7.3 æ ¼å¼ ===
    data_dict = {}
    f = h5py.File(file_path, 'r')  # ä»…æ‰“å¼€ï¼Œä¸è¯»å…¥å…¨éƒ¨å†…å­˜

    for key in f.keys():
        try:
            if lazy:
                # æ‡’åŠ è½½ï¼šä»…ä¿ç•™å¼•ç”¨ï¼Œä¸æŠŠæ•°æ®åŠ è½½è¿›å†…å­˜
                data_dict[key] = f[key]
                print(f"  ğŸ”¹ æ‡’åŠ è½½å˜é‡: {key}, shape={f[key].shape}")
            else:
                # å…¨é‡åŠ è½½ï¼šç›´æ¥è¯»ä¸º numpy æ•°ç»„ï¼ˆå å†…å­˜ï¼‰
                data_dict[key] = np.array(f[key])
                print(f"  âœ… å·²åŠ è½½å˜é‡: {key}, shape={data_dict[key].shape}")
        except Exception as e2:
            print(f"  âš ï¸ æ— æ³•åŠ è½½ {key}: {e2}")

    if not data_dict:
        raise ValueError(f"âŒ æœªèƒ½åœ¨ {file_path} ä¸­åŠ è½½æœ‰æ•ˆå˜é‡")

    print(f"âœ… æˆåŠŸåŠ è½½ {len(data_dict)} ä¸ªå˜é‡ï¼ˆ{'lazy' if lazy else 'eager'} æ¨¡å¼ï¼‰")
    return data_dict

def print_mat_file_info(data_dir: str = "./data/SimDataset"):
    """ä¸´æ—¶å‡½æ•°ï¼šæ‰“å°SimDatasetæ–‡ä»¶å¤¹ä¸‹MATæ–‡ä»¶çš„æ•°æ®å’Œæ ‡ç­¾ä¿¡æ¯"""
    import os
    
    print("=== SimDatasetæ–‡ä»¶å¤¹ä¸‹MATæ–‡ä»¶ä¿¡æ¯ ===")
    
    for file_name in os.listdir(data_dir):
        if file_name.endswith('.mat'):
            file_path = os.path.join(data_dir, file_name)
            print(f"\næ–‡ä»¶: {file_name}")
            print(f"è·¯å¾„: {file_path}")
            
            try:
                # å…ˆå°è¯•scipy.ioåŠ è½½
                try:
                    mat_data = scipy.io.loadmat(file_path)
                    print("æ–‡ä»¶å†…å®¹ (scipy.io):")
                    for key, value in mat_data.items():
                        if not key.startswith('__'):  # è·³è¿‡MATLABå…ƒæ•°æ®
                            if isinstance(value, np.ndarray):
                                print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
                                if value.size < 20:  # å¦‚æœæ•°æ®é‡å°ï¼Œæ‰“å°å†…å®¹
                                    print(f"    å†…å®¹: {value}")
                            else:
                                print(f"  {key}: {type(value)} = {value}")
                except Exception as e1:
                    if "HDF reader" in str(e1):
                        # ä½¿ç”¨h5pyåŠ è½½v7.3æ ¼å¼
                        print("æ–‡ä»¶å†…å®¹ (h5py):")
                        with h5py.File(file_path, 'r') as f:
                            def print_h5_structure(name, obj):
                                if isinstance(obj, h5py.Dataset):
                                    print(f"  {name}: shape={obj.shape}, dtype={obj.dtype}")
                                    if obj.size < 20:  # å¦‚æœæ•°æ®é‡å°ï¼Œæ‰“å°å†…å®¹
                                        print(f"    å†…å®¹: {obj[:]}")
                                elif isinstance(obj, h5py.Group):
                                    print(f"  {name}: Group")
                            
                            f.visititems(print_h5_structure)
                    else:
                        raise e1
                
                # å°è¯•ä½¿ç”¨load_mat_dataå‡½æ•°
                data = load_mat_data(file_path)
                print(f"load_mat_dataæå–çš„æ•°æ®: shape={data.shape}, dtype={data.dtype}")
                
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    
    print("\n=== ä¿¡æ¯æ‰“å°å®Œæˆ ===")


def print_detailed_dataset_info(data_dir: str = "./data/SimDataset"):
    """è¯¦ç»†æ‰“å°æ¯ä¸ªæ•°æ®é›†çš„æ•°æ®ç»“æ„å’Œæ ‡ç­¾ä¿¡æ¯"""
    import os
    
    print("=" * 80)
    print("SimDatasetæ–‡ä»¶å¤¹ä¸‹MATæ–‡ä»¶è¯¦ç»†æ•°æ®ç»“æ„åˆ†æ")
    print("=" * 80)
    
    for file_name in sorted(os.listdir(data_dir)):
        if file_name.endswith('.mat'):
            file_path = os.path.join(data_dir, file_name)
            print(f"\n{'='*60}")
            print(f"ğŸ“ æ–‡ä»¶: {file_name}")
            print(f"ğŸ“‚ è·¯å¾„: {file_path}")
            print(f"{'='*60}")
            
            try:
                # ä½¿ç”¨h5pyåŠ è½½v7.3æ ¼å¼
                with h5py.File(file_path, 'r') as f:
                    print("ğŸ“Š æ•°æ®ç»“æ„:")
                    
                    # æ”¶é›†æ‰€æœ‰æ•°æ®é›†ä¿¡æ¯
                    datasets_info = []
                    def collect_info(name, obj):
                        if isinstance(obj, h5py.Dataset):
                            datasets_info.append((name, obj))
                    
                    f.visititems(collect_info)
                    
                    # æŒ‰åç§°æ’åºå¹¶æ‰“å°
                    for name, obj in sorted(datasets_info):
                        print(f"  ğŸ”¹ {name}:")
                        print(f"     ğŸ“ å½¢çŠ¶: {obj.shape}")
                        print(f"     ğŸ·ï¸  æ•°æ®ç±»å‹: {obj.dtype}")
                        print(f"     ğŸ“ æ€»å…ƒç´ æ•°: {obj.size:,}")
                        
                        # æ‰“å°æ•°æ®èŒƒå›´
                        if obj.size > 0:
                            data_array = np.array(obj)
                            print(f"     ğŸ“ˆ æ•°å€¼èŒƒå›´: [{data_array.min():.6f}, {data_array.max():.6f}]")
                            print(f"     ğŸ“Š å‡å€¼: {data_array.mean():.6f}")
                            print(f"     ğŸ“Š æ ‡å‡†å·®: {data_array.std():.6f}")
                            
                            # å¦‚æœæ•°æ®é‡å°ï¼Œæ‰“å°éƒ¨åˆ†å†…å®¹
                            if obj.size <= 20:
                                print(f"     ğŸ“‹ å†…å®¹: {data_array}")
                            elif obj.size <= 100:
                                print(f"     ğŸ“‹ å‰10ä¸ªå€¼: {data_array.flatten()[:10]}")
                            else:
                                print(f"     ğŸ“‹ å‰5ä¸ªå€¼: {data_array.flatten()[:5]}")
                        print()
                
                # ä½¿ç”¨load_mat_dataå‡½æ•°æå–ä¸»è¦æ•°æ®
                print("ğŸ¯ load_mat_dataæå–çš„ä¸»è¦æ•°æ®:")
                data = load_mat_data(file_path)
                print(f"   ğŸ“ å½¢çŠ¶: {data.shape}")
                print(f"   ğŸ·ï¸  æ•°æ®ç±»å‹: {data.dtype}")
                print(f"   ğŸ“ æ€»å…ƒç´ æ•°: {data.size:,}")
                print(f"   ğŸ“ˆ æ•°å€¼èŒƒå›´: [{data.min():.6f}, {data.max():.6f}]")
                print(f"   ğŸ“Š å‡å€¼: {data.mean():.6f}")
                print(f"   ğŸ“Š æ ‡å‡†å·®: {data.std():.6f}")
                
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    
    print(f"\n{'='*80}")
    print("ğŸ“‹ æ•°æ®é›†æ€»ç»“:")
    print("  ğŸ”¹ train_dataset1_HP_better_range_1000.mat: è®­ç»ƒæ•°æ®ï¼ŒåŒ…å«5ç§æ ‡ç­¾")
    print("  ğŸ”¹ val_dataset1_HP_better_range_1000.mat: éªŒè¯æ•°æ®ï¼ŒåŒ…å«5ç§æ ‡ç­¾") 
    print("  ğŸ”¹ real_data_control.mat: å¥åº·äººçœŸå®æ•°æ®ï¼Œåªæœ‰æ•°é‡æ ‡ç­¾")
    print("  ğŸ”¹ real_data_sci.mat: ç—…äººçœŸå®æ•°æ®ï¼Œåªæœ‰æ•°é‡æ ‡ç­¾")
    print("=" * 80)


