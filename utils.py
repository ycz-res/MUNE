"""
å·¥å…·å‡½æ•°æ¨¡å—
åŒ…å«å„ç§è¾…åŠ©åŠŸèƒ½
"""

import torch
import os
import random
from typing import Dict
import numpy as np
import scipy.io
import h5py

def set_seed(seed: int) -> None:
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = False

def load_mat_data(file_path: str) -> Dict[str, np.ndarray]:
    """åŠ è½½MATæ–‡ä»¶æ•°æ®ï¼Œè¿”å›åŒ…å«æ‰€æœ‰å­—æ®µçš„å­—å…¸"""
    try:
        # å°è¯•ä½¿ç”¨scipy.ioåŠ è½½
        mat_data = scipy.io.loadmat(file_path)
        
        # è¿‡æ»¤æ‰MATLABå…ƒæ•°æ®å­—æ®µ
        filtered_data = {}
        for key, value in mat_data.items():
            if not key.startswith('__') and isinstance(value, np.ndarray):
                filtered_data[key] = value
        
        if filtered_data:
            return filtered_data
        else:
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®å­—æ®µ")
                
    except Exception as e:
        if "HDF reader" in str(e): 
            # ä½¿ç”¨h5pyåŠ è½½v7.3æ ¼å¼
            with h5py.File(file_path, 'r') as f:
                filtered_data = {}
                def collect_data(name, obj):
                    if isinstance(obj, h5py.Dataset):
                        filtered_data[name] = np.array(obj)
                
                f.visititems(collect_data)
                
                if filtered_data:
                    return filtered_data
                else:
                    raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®å­—æ®µ")
        else:
            raise e
    
    raise ValueError(f"æ— æ³•åŠ è½½MATæ–‡ä»¶: {file_path}")


def print_mat_file_info(data_dir: str = "./data/SimDataset"):
    """ä¸´æ—¶å‡½æ•°ï¼šæ‰“å°SimDatasetæ–‡ä»¶å¤¹ä¸‹MATæ–‡ä»¶çš„æ•°æ®å’Œæ ‡ç­¾ä¿¡æ¯"""
    import os
    
    print("=== SimDatasetæ–‡ä»¶å¤¹ä¸‹MATæ–‡ä»¶ä¿¡æ¯ ===")
    
    for file_name in os.listdir(data_dir):
        if file_name.endswith('.mat'):
            file_path = os.path.join(data_dir, file_name)
            print(f"\næ–‡ä»¶: {file_name}")
            print(f"è·¯å¾„: {file_path}")
            
            try:
                # å…ˆå°è¯•scipy.ioåŠ è½½
                try:
                    mat_data = scipy.io.loadmat(file_path)
                    print("æ–‡ä»¶å†…å®¹ (scipy.io):")
                    for key, value in mat_data.items():
                        if not key.startswith('__'):  # è·³è¿‡MATLABå…ƒæ•°æ®
                            if isinstance(value, np.ndarray):
                                print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
                                if value.size < 20:  # å¦‚æœæ•°æ®é‡å°ï¼Œæ‰“å°å†…å®¹
                                    print(f"    å†…å®¹: {value}")
                            else:
                                print(f"  {key}: {type(value)} = {value}")
                except Exception as e1:
                    if "HDF reader" in str(e1):
                        # ä½¿ç”¨h5pyåŠ è½½v7.3æ ¼å¼
                        print("æ–‡ä»¶å†…å®¹ (h5py):")
                        with h5py.File(file_path, 'r') as f:
                            def print_h5_structure(name, obj):
                                if isinstance(obj, h5py.Dataset):
                                    print(f"  {name}: shape={obj.shape}, dtype={obj.dtype}")
                                    if obj.size < 20:  # å¦‚æœæ•°æ®é‡å°ï¼Œæ‰“å°å†…å®¹
                                        print(f"    å†…å®¹: {obj[:]}")
                                elif isinstance(obj, h5py.Group):
                                    print(f"  {name}: Group")
                            
                            f.visititems(print_h5_structure)
                    else:
                        raise e1
                
                # å°è¯•ä½¿ç”¨load_mat_dataå‡½æ•°
                data = load_mat_data(file_path)
                print(f"load_mat_dataæå–çš„æ•°æ®: shape={data.shape}, dtype={data.dtype}")
                
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    
    print("\n=== ä¿¡æ¯æ‰“å°å®Œæˆ ===")


def print_detailed_dataset_info(data_dir: str = "./data/SimDataset"):
    """è¯¦ç»†æ‰“å°æ¯ä¸ªæ•°æ®é›†çš„æ•°æ®ç»“æ„å’Œæ ‡ç­¾ä¿¡æ¯"""
    import os
    
    print("=" * 80)
    print("SimDatasetæ–‡ä»¶å¤¹ä¸‹MATæ–‡ä»¶è¯¦ç»†æ•°æ®ç»“æ„åˆ†æ")
    print("=" * 80)
    
    for file_name in sorted(os.listdir(data_dir)):
        if file_name.endswith('.mat'):
            file_path = os.path.join(data_dir, file_name)
            print(f"\n{'='*60}")
            print(f"ğŸ“ æ–‡ä»¶: {file_name}")
            print(f"ğŸ“‚ è·¯å¾„: {file_path}")
            print(f"{'='*60}")
            
            try:
                # ä½¿ç”¨h5pyåŠ è½½v7.3æ ¼å¼
                with h5py.File(file_path, 'r') as f:
                    print("ğŸ“Š æ•°æ®ç»“æ„:")
                    
                    # æ”¶é›†æ‰€æœ‰æ•°æ®é›†ä¿¡æ¯
                    datasets_info = []
                    def collect_info(name, obj):
                        if isinstance(obj, h5py.Dataset):
                            datasets_info.append((name, obj))
                    
                    f.visititems(collect_info)
                    
                    # æŒ‰åç§°æ’åºå¹¶æ‰“å°
                    for name, obj in sorted(datasets_info):
                        print(f"  ğŸ”¹ {name}:")
                        print(f"     ğŸ“ å½¢çŠ¶: {obj.shape}")
                        print(f"     ğŸ·ï¸  æ•°æ®ç±»å‹: {obj.dtype}")
                        print(f"     ğŸ“ æ€»å…ƒç´ æ•°: {obj.size:,}")
                        
                        # æ‰“å°æ•°æ®èŒƒå›´
                        if obj.size > 0:
                            data_array = np.array(obj)
                            print(f"     ğŸ“ˆ æ•°å€¼èŒƒå›´: [{data_array.min():.6f}, {data_array.max():.6f}]")
                            print(f"     ğŸ“Š å‡å€¼: {data_array.mean():.6f}")
                            print(f"     ğŸ“Š æ ‡å‡†å·®: {data_array.std():.6f}")
                            
                            # å¦‚æœæ•°æ®é‡å°ï¼Œæ‰“å°éƒ¨åˆ†å†…å®¹
                            if obj.size <= 20:
                                print(f"     ğŸ“‹ å†…å®¹: {data_array}")
                            elif obj.size <= 100:
                                print(f"     ğŸ“‹ å‰10ä¸ªå€¼: {data_array.flatten()[:10]}")
                            else:
                                print(f"     ğŸ“‹ å‰5ä¸ªå€¼: {data_array.flatten()[:5]}")
                        print()
                
                # ä½¿ç”¨load_mat_dataå‡½æ•°æå–ä¸»è¦æ•°æ®
                print("ğŸ¯ load_mat_dataæå–çš„ä¸»è¦æ•°æ®:")
                data = load_mat_data(file_path)
                print(f"   ğŸ“ å½¢çŠ¶: {data.shape}")
                print(f"   ğŸ·ï¸  æ•°æ®ç±»å‹: {data.dtype}")
                print(f"   ğŸ“ æ€»å…ƒç´ æ•°: {data.size:,}")
                print(f"   ğŸ“ˆ æ•°å€¼èŒƒå›´: [{data.min():.6f}, {data.max():.6f}]")
                print(f"   ğŸ“Š å‡å€¼: {data.mean():.6f}")
                print(f"   ğŸ“Š æ ‡å‡†å·®: {data.std():.6f}")
                
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    
    print(f"\n{'='*80}")
    print("ğŸ“‹ æ•°æ®é›†æ€»ç»“:")
    print("  ğŸ”¹ train_dataset1_HP_better_range_1000.mat: è®­ç»ƒæ•°æ®ï¼ŒåŒ…å«5ç§æ ‡ç­¾")
    print("  ğŸ”¹ val_dataset1_HP_better_range_1000.mat: éªŒè¯æ•°æ®ï¼ŒåŒ…å«5ç§æ ‡ç­¾") 
    print("  ğŸ”¹ real_data_control.mat: å¥åº·äººçœŸå®æ•°æ®ï¼Œåªæœ‰æ•°é‡æ ‡ç­¾")
    print("  ğŸ”¹ real_data_sci.mat: ç—…äººçœŸå®æ•°æ®ï¼Œåªæœ‰æ•°é‡æ ‡ç­¾")
    print("=" * 80)


