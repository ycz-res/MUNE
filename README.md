# MUNE - æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶

ä¸€ä¸ªç²¾ç®€ä½†åŠŸèƒ½å®Œæ•´çš„æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ã€æ•°æ®é›†å’Œè®­ç»ƒç­–ç•¥ã€‚

## ç‰¹æ€§

- ğŸš€ **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„æ¨¡å—åˆ†ç¦»ï¼Œæ˜“äºæ‰©å±•
- ğŸ“Š **å¤šç§æ¨¡å‹**: æ”¯æŒCNNã€MLPç­‰å¸¸è§æ¶æ„
- ğŸ—‚ï¸ **æ•°æ®é›†æ”¯æŒ**: å†…ç½®MNISTã€CIFAR-10ç­‰æ•°æ®é›†
- ğŸ“ˆ **ä¸°å¯ŒæŒ‡æ ‡**: å‡†ç¡®ç‡ã€F1åˆ†æ•°ã€AUCç­‰å¤šç§è¯„ä¼°æŒ‡æ ‡
- âš™ï¸ **çµæ´»é…ç½®**: æ”¯æŒYAML/JSONé…ç½®æ–‡ä»¶
- ğŸ“ **å®Œæ•´æ—¥å¿—**: è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—å’ŒæŒ‡æ ‡è®°å½•
- ğŸ”„ **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ—©åœç­–ç•¥
- ğŸ’¾ **æ£€æŸ¥ç‚¹**: è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤è®­ç»ƒçŠ¶æ€

## é¡¹ç›®ç»“æ„

```
MUNE/
â”œâ”€â”€ model.py          # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ dataset.py        # æ•°æ®é›†å¤„ç†
â”œâ”€â”€ train.py          # è®­ç»ƒé€»è¾‘
â”œâ”€â”€ loss.py           # æŸå¤±å‡½æ•°
â”œâ”€â”€ metrics.py        # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ config.py         # é…ç½®ç®¡ç†
â”œâ”€â”€ utils.py          # å·¥å…·å‡½æ•°
â”œâ”€â”€ logger.py         # æ—¥å¿—ç³»ç»Ÿ
â”œâ”€â”€ main.py           # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ requirements.txt  # ä¾èµ–åŒ…
â”œâ”€â”€ data/             # æ•°æ®ç›®å½•
â”œâ”€â”€ logs/             # æ—¥å¿—ç›®å½•
â””â”€â”€ checkpoints/      # æ¨¡å‹æ£€æŸ¥ç‚¹
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. è®­ç»ƒä»¿çœŸæ•°æ®é›†

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒä»¿çœŸæ•°æ®é›†
python main.py --model simple_mlp --epochs 10

# ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°
python main.py --model simple_mlp --epochs 50 --batch_size 128 --lr 0.01
```

### 3. ä½¿ç”¨é…ç½®æ–‡ä»¶

```python
# åˆ›å»ºé…ç½®æ–‡ä»¶
from config import create_sim_config
config = create_sim_config()
config.to_yaml('config.yaml')

# ä½¿ç”¨é…ç½®æ–‡ä»¶è®­ç»ƒ
python main.py --config config.yaml
```

### 4. ä¼˜é›…çš„é…ç½®è¯­æ³•

```python
from config import Config

# åˆ›å»ºé…ç½®
config = Config()

# ä½¿ç”¨ç‚¹å·è¯­æ³•è®¿é—®å’Œè®¾ç½®é…ç½®
config['model.name'] = 'simple_mlp'
config['model.config.input_size'] = 1000
config['dataset.batch_size'] = 32
config['optimizer.lr'] = 0.001

# è·å–é…ç½®
print(f"æ¨¡å‹åç§°: {config['model.name']}")
print(f"å­¦ä¹ ç‡: {config['optimizer.lr']}")

# ä½¿ç”¨getæ–¹æ³•ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
device = config.get('training.device', 'cpu')

# æ›´æ–°é…ç½®
config.update({
    'training.num_epochs': 100,
    'dataset.batch_size': 64
})

# ä¿å­˜é…ç½®
config.to_yaml('my_config.yaml')
```

### 5. è®­ç»ƒHPæ•°æ®é›†

```bash
# è®­ç»ƒHPæ•°æ®é›†ï¼ˆéœ€è¦å°†MATLABæ–‡ä»¶æ”¾åœ¨./dataç›®å½•ä¸‹ï¼‰
python train_hp.py --data_root ./data --model simple_mlp --epochs 100

# åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯•
python train_hp.py --data_root ./data --eval_only --resume ./checkpoints/best_model.pth --test_real_data
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬è®­ç»ƒ

```python
from config import create_sim_config
from train import Trainer
from dataset import create_dataset, create_dataloader

# åˆ›å»ºé…ç½®
config = create_sim_config()

# åˆ›å»ºæ•°æ®é›†
train_dataset = create_dataset('sim', config['dataset'], train=True)
train_loader = create_dataloader(train_dataset, config['dataset'], train=True)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = Trainer(config)

# å¼€å§‹è®­ç»ƒ
results = trainer.train(train_loader, val_loader, num_epochs=50)
```

### è‡ªå®šä¹‰æ¨¡å‹

```python
from model import BaseModel, create_model

# å®šä¹‰è‡ªå®šä¹‰æ¨¡å‹
class MyModel(BaseModel):
    def _build_model(self):
        # å®ç°æ¨¡å‹æ¶æ„
        pass
    
    def forward(self, x):
        # å®ç°å‰å‘ä¼ æ’­
        pass

# æ³¨å†Œæ¨¡å‹
models = {'my_model': MyModel}

# ä½¿ç”¨æ¨¡å‹
model = create_model('my_model', config)
```

### è‡ªå®šä¹‰æŸå¤±å‡½æ•°

```python
from loss import BaseLoss, create_loss

# å®šä¹‰è‡ªå®šä¹‰æŸå¤±
class MyLoss(BaseLoss):
    def forward(self, predictions, targets):
        # å®ç°æŸå¤±è®¡ç®—
        pass

# æ³¨å†ŒæŸå¤±å‡½æ•°
losses = {'my_loss': MyLoss}

# ä½¿ç”¨æŸå¤±å‡½æ•°
criterion = create_loss('my_loss', config)
```

## é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®

```yaml
model:
  name: simple_mlp  # æ¨¡å‹åç§°
  config:
    input_size: 1000
    hidden_sizes: [512, 256, 128]
    num_classes: 2
    dropout_rate: 0.5
```

### æ•°æ®é›†é…ç½®

```yaml
dataset:
  name: sim
  data_path: ./data
  batch_size: 32
  num_workers: 4
```

### è®­ç»ƒé…ç½®

```yaml
training:
  num_epochs: 100
  device: auto
  save_dir: ./checkpoints
  early_stopping_patience: 10
```

## æ”¯æŒçš„æ¨¡å‹

- `simple_mlp`: ç®€å•å¤šå±‚æ„ŸçŸ¥æœº
- `simple_cnn`: ç®€å•å·ç§¯ç¥ç»ç½‘ç»œ

## æ”¯æŒçš„æ•°æ®é›†

- `sim`: ä»¿çœŸæ•°æ®é›†ï¼ˆMATæ–‡ä»¶æ ¼å¼ï¼‰

## æ”¯æŒçš„æŸå¤±å‡½æ•°

- `cross_entropy`: äº¤å‰ç†µæŸå¤±
- `focal`: Focal Loss
- `label_smoothing`: æ ‡ç­¾å¹³æ»‘æŸå¤±
- `mse`: å‡æ–¹è¯¯å·®æŸå¤±
- `combined`: ç»„åˆæŸå¤±

## æ”¯æŒçš„æŒ‡æ ‡

- `accuracy`: å‡†ç¡®ç‡
- `precision_recall_f1`: ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- `confusion_matrix`: æ··æ·†çŸ©é˜µ
- `auroc`: AUC-ROC
- `loss`: æŸå¤±å€¼

## å‘½ä»¤è¡Œå‚æ•°

```bash
python main.py --help
```

ä¸»è¦å‚æ•°ï¼š
- `--config`: é…ç½®æ–‡ä»¶è·¯å¾„
- `--dataset`: æ•°æ®é›†åç§°
- `--model`: æ¨¡å‹åç§°
- `--epochs`: è®­ç»ƒè½®æ•°
- `--batch_size`: æ‰¹æ¬¡å¤§å°
- `--lr`: å­¦ä¹ ç‡
- `--device`: è®¾å¤‡é€‰æ‹©
- `--resume`: æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹

## æ‰©å±•æŒ‡å—

### æ·»åŠ æ–°æ¨¡å‹

1. ç»§æ‰¿ `BaseModel` ç±»
2. å®ç° `_build_model` å’Œ `forward` æ–¹æ³•
3. åœ¨ `create_model` å‡½æ•°ä¸­æ³¨å†Œ

### æ·»åŠ æ–°æ•°æ®é›†

1. ç»§æ‰¿ `BaseDataset` ç±»
2. å®ç° `_load_data` æ–¹æ³•
3. åœ¨ `create_dataset` å‡½æ•°ä¸­æ³¨å†Œ

### æ·»åŠ æ–°æŸå¤±å‡½æ•°

1. ç»§æ‰¿ `BaseLoss` ç±»
2. å®ç° `forward` æ–¹æ³•
3. åœ¨ `create_loss` å‡½æ•°ä¸­æ³¨å†Œ

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼
