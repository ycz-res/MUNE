"""
MUé˜ˆå€¼é¢„æµ‹ä»»åŠ¡å¯è§†åŒ–æ¨¡å— - ç®€åŒ–ç‰ˆæœ¬
ä¸“æ³¨äºè®­ç»ƒæŸå¤±æ›²çº¿å’ŒéªŒè¯é›†é˜ˆå€¼åˆ†å¸ƒåˆ†æ
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
import torch
import warnings

# å±è”½ä¸­æ–‡å­—ä½“è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, message='.*Glyph.*missing from font.*')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
plt.style.use('default')


class MUThresholdVisualizer:
    """MUé˜ˆå€¼é¢„æµ‹ä»»åŠ¡å¯è§†åŒ–å™¨ - ç®€åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, save_dir: str):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            save_dir: ä¿å­˜å›¾è¡¨çš„ç›®å½•
        """
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
        # è®­ç»ƒå†å²æ•°æ®
        self.train_losses = []
        self.val_losses = []
        self.test_losses = []
        self.epochs = []
        
        # éªŒè¯é›†æŒ‡æ ‡å†å²
        self.val_metrics = {
            'precision': [],
            'recall': [],
            'f1': [],
            'iou': [],
            'score': []
        }
        
        # éªŒè¯é›†é¢„æµ‹æ•°æ®ï¼ˆç”¨äºé˜ˆå€¼åˆ†å¸ƒåˆ†æï¼‰
        self.val_predictions = []  # å­˜å‚¨æ¯ä¸ªepochçš„éªŒè¯é›†é¢„æµ‹
        self.val_targets = []      # å­˜å‚¨æ¯ä¸ªepochçš„éªŒè¯é›†çœŸå®æ ‡ç­¾
        
        # æ ·æœ¬çº§ç»Ÿè®¡æ•°æ®
        self.mu_count_stats = {
            'true_counts': [],      # æ¯è½®çš„çœŸå®MUæ•°é‡
            'pred_counts': [],      # æ¯è½®çš„é¢„æµ‹MUæ•°é‡
            'epochs': []            # å¯¹åº”çš„epoch
        }
        
        self.threshold_stats = {
            'true_positions': [],   # æ¯è½®çš„çœŸå®é˜ˆå€¼ä½ç½®
            'pred_positions': [],   # æ¯è½®çš„é¢„æµ‹é˜ˆå€¼ä½ç½®
            'epochs': []            # å¯¹åº”çš„epoch
        }
        
    def update_epoch(self, epoch: int, train_loss: float, val_loss: float, 
                    test_loss: Optional[float] = None, val_metrics: Optional[Dict] = None,
                    val_pred: Optional[torch.Tensor] = None, val_target: Optional[torch.Tensor] = None):
        """
        æ›´æ–°ä¸€ä¸ªepochçš„è®­ç»ƒæ•°æ®
        
        Args:
            epoch: å½“å‰epoch
            train_loss: è®­ç»ƒæŸå¤±
            val_loss: éªŒè¯æŸå¤±
            test_loss: æµ‹è¯•æŸå¤±ï¼ˆå¯é€‰ï¼‰
            val_metrics: éªŒè¯æŒ‡æ ‡ï¼ˆå¯é€‰ï¼‰
            val_pred: éªŒè¯é›†é¢„æµ‹ç»“æœï¼ˆå¯é€‰ï¼‰
            val_target: éªŒè¯é›†çœŸå®æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
        """
        self.epochs.append(epoch)
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        if test_loss is not None:
            self.test_losses.append(test_loss)
        
        # æ›´æ–°éªŒè¯æŒ‡æ ‡
        if val_metrics:
            for key in self.val_metrics:
                if key in val_metrics:
                    self.val_metrics[key].append(val_metrics[key])
                else:
                    self.val_metrics[key].append(0.0)
        
        # å­˜å‚¨éªŒè¯é›†é¢„æµ‹æ•°æ®ï¼ˆç”¨äºé˜ˆå€¼åˆ†å¸ƒåˆ†æï¼‰
        if val_pred is not None and val_target is not None:
            pred_np = val_pred.detach().cpu().numpy()
            target_np = val_target.detach().cpu().numpy()
            
            self.val_predictions.append(pred_np)
            self.val_targets.append(target_np)
            
            # è®¡ç®—æ ·æœ¬çº§ç»Ÿè®¡
            self._update_sample_stats(epoch, pred_np, target_np)
    
    def _update_sample_stats(self, epoch: int, pred: np.ndarray, target: np.ndarray, threshold: float = 0.1):
        """
        æ›´æ–°æ ·æœ¬çº§ç»Ÿè®¡æ•°æ®
        
        Args:
            epoch: å½“å‰epoch
            pred: é¢„æµ‹ç»“æœ (N, 500)
            target: çœŸå®æ ‡ç­¾ (N, 500)
            threshold: äºŒå€¼åŒ–é˜ˆå€¼
        """
        # å°†é¢„æµ‹è½¬æ¢ä¸ºæ¦‚ç‡å¹¶äºŒå€¼åŒ–
        prob = torch.sigmoid(torch.tensor(pred)).numpy()
        pred_binary = (prob >= threshold).astype(float)
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„MUæ•°é‡ï¼ˆæ¿€æ´»ä½ç½®æ•°ï¼‰
        true_mu_counts = np.sum(target, axis=1)  # (N,)
        pred_mu_counts = np.sum(pred_binary, axis=1)  # (N,)
        
        # å­˜å‚¨MUæ•°é‡ç»Ÿè®¡
        self.mu_count_stats['true_counts'].append(true_mu_counts)
        self.mu_count_stats['pred_counts'].append(pred_mu_counts)
        self.mu_count_stats['epochs'].append(epoch)
        
        # è®¡ç®—é˜ˆå€¼ä½ç½®ç»Ÿè®¡ï¼ˆæ¯ä¸ªæ ·æœ¬çš„é˜ˆå€¼ä½ç½®ï¼‰
        true_positions = []
        pred_positions = []
        
        for i in range(len(target)):
            # çœŸå®é˜ˆå€¼ä½ç½®
            true_pos = np.where(target[i] > 0)[0].tolist()
            true_positions.append(true_pos)
            
            # é¢„æµ‹é˜ˆå€¼ä½ç½®
            pred_pos = np.where(pred_binary[i] > 0)[0].tolist()
            pred_positions.append(pred_pos)
        
        # å­˜å‚¨é˜ˆå€¼ä½ç½®ç»Ÿè®¡
        self.threshold_stats['true_positions'].append(true_positions)
        self.threshold_stats['pred_positions'].append(pred_positions)
        self.threshold_stats['epochs'].append(epoch)
    
    def plot_loss_curves(self):
        """ç»˜åˆ¶è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æŸå¤±æ›²çº¿"""
        plt.figure(figsize=(16, 12))
        
        # 1. æŸå¤±æ›²çº¿
        plt.subplot(3, 3, 1)
        plt.plot(self.epochs, self.train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2, marker='o', markersize=4)
        plt.plot(self.epochs, self.val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2, marker='s', markersize=4)
        if self.test_losses:
            plt.plot(self.epochs, self.test_losses, 'g-', label='æµ‹è¯•æŸå¤±', linewidth=2, marker='^', markersize=4)
        
        plt.xlabel('Epoch')
        plt.ylabel('æŸå¤±å€¼')
        plt.title('è®­ç»ƒè¿‡ç¨‹æŸå¤±æ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. éªŒè¯æŒ‡æ ‡æ›²çº¿
        plt.subplot(3, 3, 2)
        if self.val_metrics['score']:
            plt.plot(self.epochs, self.val_metrics['score'], 'purple', label='ç»¼åˆåˆ†æ•°', linewidth=2, marker='o')
            plt.plot(self.epochs, self.val_metrics['f1'], 'orange', label='F1åˆ†æ•°', linewidth=2, marker='s')
            plt.plot(self.epochs, self.val_metrics['iou'], 'green', label='IoU', linewidth=2, marker='^')
            plt.plot(self.epochs, self.val_metrics['precision'], 'blue', label='ç²¾ç¡®ç‡', linewidth=2, marker='d')
            plt.plot(self.epochs, self.val_metrics['recall'], 'red', label='å¬å›ç‡', linewidth=2, marker='v')
        
        plt.xlabel('Epoch')
        plt.ylabel('æŒ‡æ ‡å€¼')
        plt.title('éªŒè¯é›†æŒ‡æ ‡å˜åŒ–')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 3. æŸå¤±å˜åŒ–ç‡ï¼ˆæ¢¯åº¦ï¼‰
        plt.subplot(3, 3, 3)
        if len(self.train_losses) > 1:
            train_grad = np.gradient(self.train_losses)
            val_grad = np.gradient(self.val_losses)
            plt.plot(self.epochs[1:], train_grad[1:], 'b-', label='è®­ç»ƒæŸå¤±æ¢¯åº¦', linewidth=2)
            plt.plot(self.epochs[1:], val_grad[1:], 'r-', label='éªŒè¯æŸå¤±æ¢¯åº¦', linewidth=2)
            plt.xlabel('Epoch')
            plt.ylabel('æŸå¤±å˜åŒ–ç‡')
            plt.title('æŸå¤±å˜åŒ–è¶‹åŠ¿')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 4. è®­ç»ƒ/éªŒè¯æŸå¤±æ¯”å€¼
        plt.subplot(3, 3, 4)
        if len(self.train_losses) > 0 and len(self.val_losses) > 0:
            loss_ratio = np.array(self.val_losses) / (np.array(self.train_losses) + 1e-8)
            plt.plot(self.epochs, loss_ratio, 'purple', linewidth=2, marker='o', markersize=4)
            plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='ç†æƒ³æ¯”å€¼=1')
            plt.xlabel('Epoch')
            plt.ylabel('éªŒè¯æŸå¤±/è®­ç»ƒæŸå¤±')
            plt.title('è¿‡æ‹Ÿåˆç›‘æ§')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 5. æŒ‡æ ‡æ”¹å–„è¶‹åŠ¿
        plt.subplot(3, 3, 5)
        if self.val_metrics['score'] and len(self.val_metrics['score']) > 1:
            score_improvement = np.diff(self.val_metrics['score'])
            plt.plot(self.epochs[1:], score_improvement, 'green', linewidth=2, marker='o', markersize=4)
            plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)
            plt.xlabel('Epoch')
            plt.ylabel('Scoreæ”¹å–„é‡')
            plt.title('ç»¼åˆåˆ†æ•°æ”¹å–„è¶‹åŠ¿')
            plt.grid(True, alpha=0.3)
        
        # 6. ç²¾ç¡®ç‡vså¬å›ç‡æƒè¡¡
        plt.subplot(3, 3, 6)
        if self.val_metrics['precision'] and self.val_metrics['recall']:
            plt.plot(self.val_metrics['precision'], self.val_metrics['recall'], 'purple', 
                    linewidth=2, marker='o', markersize=6)
            plt.scatter(self.val_metrics['precision'][0], self.val_metrics['recall'][0], 
                       color='green', s=100, label='å¼€å§‹', zorder=5)
            plt.scatter(self.val_metrics['precision'][-1], self.val_metrics['recall'][-1], 
                       color='red', s=100, label='ç»“æŸ', zorder=5)
            plt.xlabel('ç²¾ç¡®ç‡')
            plt.ylabel('å¬å›ç‡')
            plt.title('P-Ræƒè¡¡æ›²çº¿')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 7. æŸå¤±ç»Ÿè®¡ä¿¡æ¯
        plt.subplot(3, 3, 7)
        final_train = self.train_losses[-1] if self.train_losses else 0
        final_val = self.val_losses[-1] if self.val_losses else 0
        best_train = min(self.train_losses) if self.train_losses else 0
        best_val = min(self.val_losses) if self.val_losses else 0
        
        stats_text = f"""è®­ç»ƒç»Ÿè®¡ä¿¡æ¯
        
æŸå¤±ç»Ÿè®¡:
â€¢ æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train:.6f}
â€¢ æœ€ç»ˆéªŒè¯æŸå¤±: {final_val:.6f}
â€¢ æœ€ä½³è®­ç»ƒæŸå¤±: {best_train:.6f}
â€¢ æœ€ä½³éªŒè¯æŸå¤±: {best_val:.6f}

è®­ç»ƒè½®æ•°: {len(self.epochs)}
        """
        
        if self.test_losses:
            final_test = self.test_losses[-1]
            stats_text += f"â€¢ æœ€ç»ˆæµ‹è¯•æŸå¤±: {final_test:.6f}"
        
        plt.text(0.05, 0.5, stats_text, fontsize=10, verticalalignment='center',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
        plt.axis('off')
        plt.title('è®­ç»ƒç»Ÿè®¡')
        
        # 8. æœ€ä½³æŒ‡æ ‡
        plt.subplot(3, 3, 8)
        if self.val_metrics['score']:
            best_score = max(self.val_metrics['score'])
            best_f1 = max(self.val_metrics['f1'])
            best_iou = max(self.val_metrics['iou'])
            best_precision = max(self.val_metrics['precision'])
            best_recall = max(self.val_metrics['recall'])
            
            metrics_text = f"""æœ€ä½³éªŒè¯æŒ‡æ ‡
            
â€¢ æœ€ä½³ç»¼åˆåˆ†æ•°: {best_score:.4f}
â€¢ æœ€ä½³F1åˆ†æ•°: {best_f1:.4f}
â€¢ æœ€ä½³IoU: {best_iou:.4f}
â€¢ æœ€ä½³ç²¾ç¡®ç‡: {best_precision:.4f}
â€¢ æœ€ä½³å¬å›ç‡: {best_recall:.4f}
            """
            
            plt.text(0.05, 0.5, metrics_text, fontsize=10, verticalalignment='center',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen", alpha=0.7))
        
        plt.axis('off')
        plt.title('æœ€ä½³æŒ‡æ ‡')
        
        # 9. è®­ç»ƒç¨³å®šæ€§åˆ†æ
        plt.subplot(3, 3, 9)
        if len(self.train_losses) > 2:
            # è®¡ç®—æŸå¤±çš„æ ‡å‡†å·®ï¼ˆç¨³å®šæ€§æŒ‡æ ‡ï¼‰
            train_std = np.std(self.train_losses)
            val_std = np.std(self.val_losses)
            
            stability_text = f"""è®­ç»ƒç¨³å®šæ€§åˆ†æ
            
â€¢ è®­ç»ƒæŸå¤±æ ‡å‡†å·®: {train_std:.6f}
â€¢ éªŒè¯æŸå¤±æ ‡å‡†å·®: {val_std:.6f}
â€¢ è®­ç»ƒç¨³å®šæ€§: {'ç¨³å®š' if train_std < 0.01 else 'ä¸ç¨³å®š'}
â€¢ éªŒè¯ç¨³å®šæ€§: {'ç¨³å®š' if val_std < 0.01 else 'ä¸ç¨³å®š'}
            """
            
            plt.text(0.05, 0.5, stability_text, fontsize=10, verticalalignment='center',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.7))
        
        plt.axis('off')
        plt.title('ç¨³å®šæ€§åˆ†æ')
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_threshold_distributions(self, threshold: float = 0.1):
        """
        ç»˜åˆ¶éªŒè¯é›†æ¿€æ´»é˜ˆå€¼åˆ†å¸ƒ
        
        Args:
            threshold: ç”¨äºäºŒå€¼åŒ–çš„é˜ˆå€¼
        """
        if not self.val_predictions or not self.val_targets:
            print("âš ï¸ æ²¡æœ‰éªŒè¯é›†é¢„æµ‹æ•°æ®ï¼Œè·³è¿‡é˜ˆå€¼åˆ†å¸ƒåˆ†æ")
            return
        
        # é€‰æ‹©å‡ ä¸ªå…³é”®epochè¿›è¡Œå±•ç¤º
        key_epochs = [0, len(self.epochs)//4, len(self.epochs)//2, len(self.epochs)-1]
        key_epochs = [e for e in key_epochs if e < len(self.val_predictions)]
        
        fig, axes = plt.subplots(2, len(key_epochs), figsize=(5*len(key_epochs), 10))
        if len(key_epochs) == 1:
            axes = axes.reshape(2, 1)
        
        fig.suptitle('éªŒè¯é›†æ¿€æ´»é˜ˆå€¼åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
        
        for i, epoch_idx in enumerate(key_epochs):
            epoch = self.epochs[epoch_idx]
            pred = self.val_predictions[epoch_idx]  # (N, 500)
            target = self.val_targets[epoch_idx]     # (N, 500)
            
            # å°†é¢„æµ‹è½¬æ¢ä¸ºæ¦‚ç‡å¹¶äºŒå€¼åŒ–
            prob = torch.sigmoid(torch.tensor(pred)).numpy()
            pred_binary = (prob >= threshold).astype(float)
            
            # ä¸Šæ’ï¼šé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
            axes[0, i].hist(prob.flatten(), bins=50, alpha=0.7, color='blue', density=True)
            axes[0, i].axvline(x=threshold, color='red', linestyle='--', linewidth=2, label=f'é˜ˆå€¼={threshold}')
            axes[0, i].set_xlabel('é¢„æµ‹æ¦‚ç‡')
            axes[0, i].set_ylabel('å¯†åº¦')
            axes[0, i].set_title(f'Epoch {epoch}: é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')
            axes[0, i].legend()
            axes[0, i].grid(True, alpha=0.3)
            
            # ä¸‹æ’ï¼šæ¿€æ´»ä½ç½®åˆ†å¸ƒ
            pred_positions = np.sum(pred_binary, axis=1)  # æ¯ä¸ªæ ·æœ¬çš„æ¿€æ´»ä½ç½®æ•°
            target_positions = np.sum(target, axis=1)     # æ¯ä¸ªæ ·æœ¬çš„çœŸå®ä½ç½®æ•°
            
            axes[1, i].scatter(target_positions, pred_positions, alpha=0.6, s=30)
            min_val = min(min(target_positions), min(pred_positions))
            max_val = max(max(target_positions), max(pred_positions))
            axes[1, i].plot([min_val, max_val], [min_val, max_val], 'r--', label='å®Œç¾é¢„æµ‹çº¿')
            
            # è®¡ç®—ç›¸å…³ç³»æ•°
            corr = np.corrcoef(target_positions, pred_positions)[0, 1]
            axes[1, i].text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr:.3f}', transform=axes[1, i].transAxes,
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
            
            axes[1, i].set_xlabel('çœŸå®æ¿€æ´»ä½ç½®æ•°')
            axes[1, i].set_ylabel('é¢„æµ‹æ¿€æ´»ä½ç½®æ•°')
            axes[1, i].set_title(f'Epoch {epoch}: æ¿€æ´»ä½ç½®å¯¹æ¯”')
            axes[1, i].legend()
            axes[1, i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'threshold_distributions.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_sample_comparison(self, threshold: float = 0.1):
        """
        ç»˜åˆ¶æ ·æœ¬çº§MUæ•°é‡å’Œé˜ˆå€¼ä½ç½®å¯¹æ¯”å›¾
        
        Args:
            threshold: ç”¨äºäºŒå€¼åŒ–çš„é˜ˆå€¼
        """
        if not self.mu_count_stats['epochs']:
            print("âš ï¸ æ²¡æœ‰æ ·æœ¬ç»Ÿè®¡æ•°æ®ï¼Œè·³è¿‡æ ·æœ¬å¯¹æ¯”åˆ†æ")
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('æ ·æœ¬çº§MUæ•°é‡å’Œé˜ˆå€¼ä½ç½®å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
        
        epochs = self.mu_count_stats['epochs']
        
        # 1. MUæ•°é‡é¢„æµ‹å‡†ç¡®æ€§éšæ—¶é—´å˜åŒ–
        axes[0, 0].set_title('MUæ•°é‡é¢„æµ‹å‡†ç¡®æ€§')
        for i, epoch in enumerate(epochs):
            true_counts = self.mu_count_stats['true_counts'][i]
            pred_counts = self.mu_count_stats['pred_counts'][i]
            
            # è®¡ç®—ç›¸å…³ç³»æ•°
            corr = np.corrcoef(true_counts, pred_counts)[0, 1]
            
            # ç»˜åˆ¶æ•£ç‚¹å›¾
            axes[0, 0].scatter(true_counts, pred_counts, alpha=0.6, s=20, 
                             label=f'Epoch {epoch} (r={corr:.3f})')
        
        # æ·»åŠ å®Œç¾é¢„æµ‹çº¿
        all_true = np.concatenate(self.mu_count_stats['true_counts'])
        all_pred = np.concatenate(self.mu_count_stats['pred_counts'])
        min_val = min(min(all_true), min(all_pred))
        max_val = max(max(all_true), max(all_pred))
        axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='å®Œç¾é¢„æµ‹çº¿')
        
        axes[0, 0].set_xlabel('çœŸå®MUæ•°é‡')
        axes[0, 0].set_ylabel('é¢„æµ‹MUæ•°é‡')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. MUæ•°é‡é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
        axes[0, 1].set_title('MUæ•°é‡é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
        for i, epoch in enumerate(epochs):
            true_counts = self.mu_count_stats['true_counts'][i]
            pred_counts = self.mu_count_stats['pred_counts'][i]
            errors = pred_counts - true_counts
            
            axes[0, 1].hist(errors, bins=20, alpha=0.5, label=f'Epoch {epoch}', density=True)
        
        axes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='é›¶è¯¯å·®çº¿')
        axes[0, 1].set_xlabel('é¢„æµ‹è¯¯å·® (é¢„æµ‹ - çœŸå®)')
        axes[0, 1].set_ylabel('å¯†åº¦')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. MUæ•°é‡é¢„æµ‹å‡†ç¡®æ€§è¶‹åŠ¿
        axes[0, 2].set_title('MUæ•°é‡é¢„æµ‹å‡†ç¡®æ€§è¶‹åŠ¿')
        correlations = []
        mae_scores = []
        
        for i, epoch in enumerate(epochs):
            true_counts = self.mu_count_stats['true_counts'][i]
            pred_counts = self.mu_count_stats['pred_counts'][i]
            
            corr = np.corrcoef(true_counts, pred_counts)[0, 1]
            mae = np.mean(np.abs(pred_counts - true_counts))
            
            correlations.append(corr)
            mae_scores.append(mae)
        
        ax2 = axes[0, 2].twinx()
        line1 = axes[0, 2].plot(epochs, correlations, 'b-o', linewidth=2, label='ç›¸å…³ç³»æ•°')
        line2 = ax2.plot(epochs, mae_scores, 'r-s', linewidth=2, label='MAE')
        
        axes[0, 2].set_xlabel('Epoch')
        axes[0, 2].set_ylabel('ç›¸å…³ç³»æ•°', color='b')
        ax2.set_ylabel('MAE', color='r')
        axes[0, 2].grid(True, alpha=0.3)
        
        # åˆå¹¶å›¾ä¾‹
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        axes[0, 2].legend(lines, labels, loc='upper right')
        
        # 4. é˜ˆå€¼ä½ç½®é‡å åˆ†æ
        axes[1, 0].set_title('é˜ˆå€¼ä½ç½®é‡å åˆ†æ')
        overlap_ratios = []
        
        for i, epoch in enumerate(epochs):
            true_positions = self.threshold_stats['true_positions'][i]
            pred_positions = self.threshold_stats['pred_positions'][i]
            
            overlaps = []
            for j in range(len(true_positions)):
                true_set = set(true_positions[j])
                pred_set = set(pred_positions[j])
                
                if len(true_set) > 0:
                    overlap_ratio = len(true_set & pred_set) / len(true_set)
                    overlaps.append(overlap_ratio)
                else:
                    overlaps.append(1.0 if len(pred_set) == 0 else 0.0)
            
            overlap_ratios.append(np.mean(overlaps))
        
        axes[1, 0].plot(epochs, overlap_ratios, 'g-o', linewidth=2, markersize=6)
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('å¹³å‡é‡å æ¯”ä¾‹')
        axes[1, 0].set_ylim(0, 1)
        axes[1, 0].grid(True, alpha=0.3)
        
        # 5. æ ·æœ¬é¢„æµ‹ç¤ºä¾‹ï¼ˆé€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ ·æœ¬ï¼‰
        axes[1, 1].set_title('æ ·æœ¬é¢„æµ‹ç¤ºä¾‹')
        if len(epochs) >= 2:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªepoch
            first_epoch_idx = 0
            last_epoch_idx = -1
            
            # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ ·æœ¬
            sample_indices = [0, len(self.mu_count_stats['true_counts'][0])//2, -1]
            
            for sample_idx in sample_indices:
                if sample_idx < len(self.mu_count_stats['true_counts'][0]):
                    true_count = self.mu_count_stats['true_counts'][first_epoch_idx][sample_idx]
                    pred_count_first = self.mu_count_stats['pred_counts'][first_epoch_idx][sample_idx]
                    pred_count_last = self.mu_count_stats['pred_counts'][last_epoch_idx][sample_idx]
                    
                    axes[1, 1].bar([f'æ ·æœ¬{sample_idx+1}\n(Epoch {epochs[first_epoch_idx]})', 
                                   f'æ ·æœ¬{sample_idx+1}\n(Epoch {epochs[last_epoch_idx]})'], 
                                  [true_count, true_count], alpha=0.7, label=f'çœŸå® (æ ·æœ¬{sample_idx+1})')
                    axes[1, 1].bar([f'æ ·æœ¬{sample_idx+1}\n(Epoch {epochs[first_epoch_idx]})', 
                                   f'æ ·æœ¬{sample_idx+1}\n(Epoch {epochs[last_epoch_idx]})'], 
                                  [pred_count_first, pred_count_last], alpha=0.5, 
                                  label=f'é¢„æµ‹ (æ ·æœ¬{sample_idx+1})')
        
        axes[1, 1].set_ylabel('MUæ•°é‡')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        # 6. ç»Ÿè®¡æ‘˜è¦
        axes[1, 2].set_title('ç»Ÿè®¡æ‘˜è¦')
        final_corr = correlations[-1] if correlations else 0
        final_mae = mae_scores[-1] if mae_scores else 0
        final_overlap = overlap_ratios[-1] if overlap_ratios else 0
        
        summary_text = f"""æ ·æœ¬çº§é¢„æµ‹ç»Ÿè®¡æ‘˜è¦
        
æœ€ç»ˆæ€§èƒ½:
â€¢ MUæ•°é‡ç›¸å…³ç³»æ•°: {final_corr:.4f}
â€¢ MUæ•°é‡MAE: {final_mae:.2f}
â€¢ é˜ˆå€¼ä½ç½®é‡å ç‡: {final_overlap:.4f}

è®­ç»ƒè¶‹åŠ¿:
â€¢ ç›¸å…³ç³»æ•°æ”¹å–„: {correlations[-1] - correlations[0]:.4f}
â€¢ MAEæ”¹å–„: {mae_scores[0] - mae_scores[-1]:.2f}
â€¢ é‡å ç‡æ”¹å–„: {overlap_ratios[-1] - overlap_ratios[0]:.4f}

æ ·æœ¬æ•°é‡: {len(self.mu_count_stats['true_counts'][0])}
è®­ç»ƒè½®æ•°: {len(epochs)}
        """
        
        axes[1, 2].text(0.05, 0.5, summary_text, fontsize=10, verticalalignment='center',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcyan", alpha=0.7))
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'sample_comparison.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def save_training_data(self, test_loss: float = None):
        """ä¿å­˜è®­ç»ƒæ•°æ®åˆ°CSV"""
        training_data = {
            'epoch': self.epochs,
            'train_loss': self.train_losses,
            'val_loss': self.val_losses
        }
        
        if test_loss is not None:
            training_data['test_loss'] = [test_loss] * len(self.epochs)
        
        # æ·»åŠ éªŒè¯æŒ‡æ ‡
        for key, values in self.val_metrics.items():
            if values:
                training_data[f'val_{key}'] = values
        
        df = pd.DataFrame(training_data)
        df.to_csv(os.path.join(self.save_dir, 'training_data.csv'), index=False)
    
    def generate_comprehensive_report(self, test_loss: float = None, 
                                    model_info: Dict[str, Any] = None,
                                    dataset_info: Dict[str, Any] = None,
                                    threshold: float = 0.1):
        """
        ç”Ÿæˆç»¼åˆè®­ç»ƒæŠ¥å‘Š
        
        Args:
            test_loss: æµ‹è¯•æŸå¤±
            model_info: æ¨¡å‹ä¿¡æ¯
            dataset_info: æ•°æ®é›†ä¿¡æ¯
            threshold: é˜ˆå€¼åˆ†å¸ƒåˆ†æçš„é˜ˆå€¼
        """
        # ç”ŸæˆæŸå¤±æ›²çº¿
        self.plot_loss_curves()
        
        # ç”Ÿæˆé˜ˆå€¼åˆ†å¸ƒåˆ†æ
        self.plot_threshold_distributions(threshold)
        
        # ç”Ÿæˆæ ·æœ¬çº§å¯¹æ¯”åˆ†æ
        self.plot_sample_comparison(threshold)
        
        # ä¿å­˜è®­ç»ƒæ•°æ®
        self.save_training_data(test_loss)
        
        print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {self.save_dir}/training_curves.png")
        print(f"ğŸ“ˆ é˜ˆå€¼åˆ†å¸ƒåˆ†æå·²ä¿å­˜åˆ°: {self.save_dir}/threshold_distributions.png")
        print(f"ğŸ¯ æ ·æœ¬å¯¹æ¯”åˆ†æå·²ä¿å­˜åˆ°: {self.save_dir}/sample_comparison.png")
        print(f"ğŸ“‹ è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {self.save_dir}/training_data.csv")
