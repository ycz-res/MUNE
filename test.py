"""
æµ‹è¯•æ¨¡å—
ç”¨äºåŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ€§èƒ½
å¯ä»¥ç‹¬ç«‹è¿è¡Œï¼Œä¹Ÿå¯ä»¥è¢«train.pyè°ƒç”¨
"""

import torch
import argparse
import os
import glob
import numpy as np

from dataset import Sim
from config import get_config
from model import Linear, CNN, LSTM
from metrics import b_v_metrics
from loss import ce, focal_ce, thr
import json


def get_args_parser():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser('MU Threshold Prediction Testing', add_help=False)
    parser.add_argument('--device', default='cuda', type=str, help='Device to use (cpu/cuda)')
    parser.add_argument('--model_type', default='LSTM', choices=['Linear', 'CNN', 'LSTM'], help='Model architecture type')
    parser.add_argument('--threshold_mode', default='binary', choices=['value', 'binary'], help='Threshold output mode')
    parser.add_argument('--dataset_type', default='Sim', choices=['Sim'], help='Dataset type')
    parser.add_argument('--metrics_threshold', default=0.5, type=float, help='Threshold for metrics calculation')
    parser.add_argument('--timestamp', default=None, type=str, help='Model timestamp (e.g., 20251023_123456). If provided, load {checkpoint}/best_model_{timestamp}.pth')
    parser.add_argument('--checkpoint', default='checkpoints', type=str, help='Directory containing model checkpoints')
    parser.add_argument('--batch_size', default=4, type=int, help='Batch size for testing')
    parser.add_argument('--num_collect', default=20, type=int, help='Number of samples to collect and save (0=do not collect)')
    parser.add_argument('--save_samples', default=True, type=bool, help='Save sample data in JSON')
    parser.add_argument('--loss_type', default='ce', choices=['thr', 'focal', 'ce'], help='Loss function type')
    parser.add_argument('--use_weighted_loss', default=False, type=bool, help='Use weighted loss')
    parser.add_argument('--pos_weight', default=50.0, type=float, help='Positive class weight')
    
    return parser


def get_latest_timestamp(checkpoint_dir: str = 'checkpoints'):
    """
    ä»æŒ‡å®šç›®å½•è·å–æœ€æ–°æ¨¡å‹çš„æ—¶é—´æˆ³
    
    Args:
        checkpoint_dir: checkpointç›®å½•
    
    Returns:
        timestamp: æœ€æ–°æ¨¡å‹çš„æ—¶é—´æˆ³
    """
    # æŸ¥æ‰¾æ‰€æœ‰checkpointæ–‡ä»¶
    pattern = os.path.join(checkpoint_dir, 'best_model_*.pth')
    checkpoint_files = glob.glob(pattern)
    
    if not checkpoint_files:
        raise FileNotFoundError(f"åœ¨ {checkpoint_dir} ä¸­æœªæ‰¾åˆ°checkpointæ–‡ä»¶")
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
    latest_checkpoint = max(checkpoint_files, key=os.path.getmtime)
    
    # ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³
    filename = os.path.basename(latest_checkpoint)
    timestamp = filename.replace('best_model_', '').replace('.pth', '')
    
    return timestamp


def load_best_model(model_type, timestamp, checkpoint_dir, device):
    """
    æ ¹æ®æ—¶é—´æˆ³åŠ è½½æœ€ä½³æ¨¡å‹
    
    Args:
        model_type: æ¨¡å‹ç±»å‹å­—ç¬¦ä¸²
        timestamp: æ¨¡å‹æ—¶é—´æˆ³
        checkpoint_dir: checkpointç›®å½•
        device: è®¾å¤‡
    
    Returns:
        model: åŠ è½½æƒé‡åçš„æ¨¡å‹
    """
    checkpoint_path = os.path.join(checkpoint_dir, f'best_model_{timestamp}.pth')
    
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {checkpoint_path}")
    
    # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    try:
        model = eval(model_type)().to(device)
    except (NameError, AttributeError) as e:
        raise ValueError(f"æ— æ³•åˆ›å»ºæ¨¡å‹ '{model_type}': {e}")
    
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # æ‰“å°åŠ è½½ä¿¡æ¯
    print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {checkpoint_path}")
    
    return model


def test(model, dataset, loss_fn, metrics_fn, device, threshold=0.5, 
         show_progress=True, num_collect=None, batch_size=4):
    """
    åœ¨æ•°æ®é›†ä¸Šæµ‹è¯•æ¨¡å‹ï¼ˆéšæœºé‡‡æ ·æŒ‡å®šæ•°é‡æ ·æœ¬ï¼‰
    
    Args:
        model: æ¨¡å‹
        dataset: æ•°æ®é›†
        loss_fn: æŸå¤±å‡½æ•°
        metrics_fn: æŒ‡æ ‡è®¡ç®—å‡½æ•°
        device: è®¾å¤‡
        threshold: äºŒå€¼åŒ–é˜ˆå€¼
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        num_collect: æµ‹è¯•å’Œæ”¶é›†çš„æ ·æœ¬æ•°é‡ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ•°æ®
        batch_size: æ‰¹å¤„ç†å¤§å°
    
    Returns:
        avg_loss: å¹³å‡æŸå¤±
        metrics: æŒ‡æ ‡å­—å…¸
        sample_data: æ ·æœ¬æ•°æ®å­—å…¸
    """
    model.eval()
    total_samples = len(dataset)
    
    # ç¡®å®šæµ‹è¯•æ ·æœ¬æ•°é‡
    if num_collect is None:
        num_test = total_samples
        test_indices = list(range(total_samples))
        if show_progress:
            print(f"  ğŸ” æµ‹è¯•å…¨éƒ¨æ•°æ® ({num_test} ä¸ªæ ·æœ¬)...")
    else:
        num_test = min(num_collect, total_samples)
        test_indices = torch.randperm(total_samples)[:num_test].tolist()
        if show_progress:
            if num_collect > total_samples:
                print(f"  âš ï¸  è¯·æ±‚æ ·æœ¬æ•° {num_collect} è¶…è¿‡æ•°æ®é›†å¤§å° {total_samples}ï¼Œè°ƒæ•´ä¸º {num_test}")
            print(f"  ğŸ² éšæœºé‡‡æ · {num_test} ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•...")
    
    # æ”¶é›†æ•°æ®
    cmap_list = []
    thresholds_list = []
    mus_list = []
    
    for idx in test_indices:
        cmap_data, mu_count, threshold_data = dataset[idx]
        cmap_list.append(cmap_data)
        thresholds_list.append(threshold_data)
        mus_list.append(mu_count)
    
    # è½¬æ¢ä¸ºtensorï¼ˆCPUç«¯ï¼‰
    cmap_tensor = torch.stack(cmap_list)
    thresholds_tensor = torch.stack(thresholds_list)
    
    # åˆ†æ‰¹é¢„æµ‹ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
    total_loss = 0.0
    all_preds = []
    all_targets = []
    num_batches = (num_test + batch_size - 1) // batch_size
    
    with torch.no_grad():
        for i in range(0, num_test, batch_size):
            batch_end = min(i + batch_size, num_test)
            batch_cmap = cmap_tensor[i:batch_end].to(device)
            batch_thresholds = thresholds_tensor[i:batch_end].to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(batch_cmap)
            
            # è®¡ç®—æŸå¤±
            loss = loss_fn(outputs, batch_thresholds)
            total_loss += loss.item()
            
            # äºŒå€¼åŒ–é¢„æµ‹
            preds = (torch.sigmoid(outputs) >= threshold).float()
            
            # æ”¶é›†ç»“æœ
            all_preds.append(preds.cpu())
            all_targets.append(batch_thresholds.cpu())
            
            # æ‰“å°è¿›åº¦
            if show_progress and (i // batch_size + 1) % max(1, num_batches // 5) == 0:
                progress = (i + batch_size) / num_test * 100
                print(f"    ğŸ” æµ‹è¯•è¿›åº¦: {min(i + batch_size, num_test)}/{num_test} ({progress:.0f}%)")
    
    if show_progress:
        print(f"  âœ… æµ‹è¯•å®Œæˆ: {num_test} ä¸ªæ ·æœ¬")
    
    # æ‹¼æ¥æ‰€æœ‰æ‰¹æ¬¡
    all_preds = torch.cat(all_preds, dim=0)
    all_targets = torch.cat(all_targets, dim=0)
    
    # è®¡ç®—å¹³å‡æŸå¤±å’ŒæŒ‡æ ‡
    avg_loss = total_loss / num_batches
    metrics = metrics_fn(all_preds, all_targets)
    
    # ç»„è£…æ ·æœ¬æ•°æ®
    sample_data = {
        'indices': test_indices,
        'cmap': cmap_tensor.numpy(),
        'thresholds_true': thresholds_tensor.numpy(),
        'thresholds_pred': all_preds.numpy(),
        'mus_true': torch.stack(mus_list).numpy()
    }
    
    return avg_loss, metrics, sample_data


def save_test_data(test_loss, test_metrics, sample_data, timestamp, save_samples=True):
    """ä¿å­˜æµ‹è¯•æ•°æ®"""
    print(f"\nğŸ“Š ä¿å­˜æµ‹è¯•æ•°æ®...")
    
    # ç»„è£…ä¿å­˜è·¯å¾„
    curves_dir = os.path.join('plot', 'curve_data')
    os.makedirs(curves_dir, exist_ok=True)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_data = {
        'test_loss': float(test_loss),
        'test_metrics': {k: float(v) for k, v in test_metrics.items()},
        'num_samples': len(sample_data['indices'])
    }
    
    # å¦‚æœéœ€è¦ä¿å­˜æ ·æœ¬æ•°æ®ï¼Œæ·»åŠ åˆ° JSON
    if save_samples:
        test_data['sample_data'] = {
            'indices': sample_data['indices'],
            'cmap': sample_data['cmap'].tolist(),
            'thresholds_true': sample_data['thresholds_true'].tolist(),
            'thresholds_pred': sample_data['thresholds_pred'].tolist(),
            'mus_true': sample_data['mus_true'].tolist()
        }
    
    # ä¿å­˜ä¸º JSON
    test_data_path = os.path.join(curves_dir, f'test_{timestamp}.json')
    with open(test_data_path, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æµ‹è¯•æ•°æ®å·²ä¿å­˜: {test_data_path}")


def main(args):
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # åŠ è½½é…ç½®
    config = get_config()
    
    print("=" * 50)
    print("ğŸ§ª MU Threshold Prediction - æ¨¡å‹æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    print("\nğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®é›†...")
    Dataset = eval(args.dataset_type)
    test_dataset = Dataset(
        config['SimDataset.data'], 
        args.dataset_type, 
        start_percent=0.95, 
        end_percent=1.0,
        stage='test',
        threshold_mode=args.threshold_mode
    )
    
    print(f"âœ… æµ‹è¯•é›†å¤§å°: {len(test_dataset)} ä¸ªæ ·æœ¬")
    
    # ç¡®å®šæ—¶é—´æˆ³
    if args.timestamp:
        timestamp = args.timestamp
        print(f"\nğŸ“¥ ä½¿ç”¨æŒ‡å®šæ—¶é—´æˆ³: {timestamp}")
    else:
        timestamp = get_latest_timestamp(args.checkpoint)
        print(f"\nğŸ“¥ è‡ªåŠ¨è·å–æœ€æ–°æ—¶é—´æˆ³: {timestamp}")
    
    # åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹
    print(f"\nğŸ”§ åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹: {args.model_type}")
    model = load_best_model(args.model_type, timestamp, args.checkpoint, args.device)
    
    # åˆ›å»ºæŸå¤±å‡½æ•°ï¼ˆæ”¯æŒåŠ æƒï¼‰
    if args.use_weighted_loss and args.loss_type == 'ce':
        pos_weight_tensor = torch.tensor(args.pos_weight, device=args.device)
        def loss_fn(pred, target):
            return ce(pred, target, pos_weight=pos_weight_tensor)
    else:
        loss_fn = eval(args.loss_type)
    
    # åˆ›å»ºæŒ‡æ ‡å‡½æ•°ï¼ˆä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼ï¼‰
    def metrics_fn(pred, target):
        return b_v_metrics(pred, target, threshold=args.metrics_threshold)
    
    # æ‰§è¡Œæµ‹è¯•
    print("\nğŸ§ª æµ‹è¯•é˜¶æ®µ")
    test_loss, test_metrics, sample_data = test(
        model, test_dataset, loss_fn, metrics_fn, args.device,
        threshold=args.metrics_threshold, 
        show_progress=True, 
        num_collect=args.num_collect if args.num_collect > 0 else None,
        batch_size=args.batch_size
    )
    
    # æ‰“å°æµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœ:")
    print("=" * 60)
    print(f"   Loss: {test_loss:.6f}")
    for metric_name, metric_value in test_metrics.items():
        print(f"   {metric_name}: {metric_value:.4f}")
    print("=" * 60)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    save_test_data(test_loss, test_metrics, sample_data, timestamp, save_samples=args.save_samples)


if __name__ == '__main__':
    parser = get_args_parser()
    args = parser.parse_args()
    main(args)
