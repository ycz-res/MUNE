"""
æµ‹è¯•æ¨¡å—
ç”¨äºåŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ€§èƒ½
å¯ä»¥ç‹¬ç«‹è¿è¡Œï¼Œä¹Ÿå¯ä»¥è¢«train.pyè°ƒç”¨
"""

import torch
import argparse
import os
import numpy as np
import warnings

# å¿½ç•¥ NVML è­¦å‘Š
warnings.filterwarnings('ignore', message='.*NVML.*')

from dataset import Sim
from config import get_config
from model import Linear, CNN, LSTM
from metrics import b_v_metrics
from loss import ce, focal_ce, thr, emd
import json


def get_args_parser():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser('MU Threshold Prediction Testing', add_help=False)
    parser.add_argument('--device', default='cuda', type=str, help='Device to use (cpu/cuda)')
    parser.add_argument('--model_type', default='LSTM', choices=['Linear', 'CNN', 'LSTM'], help='Model architecture type')
    parser.add_argument('--hidden_size', default=128, type=int, help='Hidden size for LSTM model (d_model, should match training)')
    parser.add_argument('--threshold_mode', default='binary', choices=['value', 'binary'], help='Threshold output mode')
    parser.add_argument('--dataset_type', default='Sim', choices=['Sim', 'Real'], help='Dataset type')
    parser.add_argument('--metrics_threshold', default=0.5, type=float, help='Threshold for metrics calculation')
    parser.add_argument('--timestamp', required=True, type=str, help='Model timestamp (e.g., 20251023_123456)')
    parser.add_argument('--result_dir', default='result', type=str, help='Root directory containing experiment results')
    parser.add_argument('--batch_size', default=4, type=int, help='Batch size for testing')
    parser.add_argument('--num_collect', default=20, type=int, help='Number of samples to collect and save (0=do not collect)')
    parser.add_argument('--save_samples', default=True, type=bool, help='Save sample data in JSON')
    parser.add_argument('--loss_type', default='emd', choices=['thr', 'focal', 'ce', 'emd'], help='Loss function type')
    parser.add_argument('--use_weighted_loss', default=True, type=bool, help='Use weighted loss')
    parser.add_argument('--pos_weight', default=7.0, type=float, help='Positive class weight')
    
    return parser




def load_best_model(model_type, timestamp, result_dir_path, device, hidden_size=64):
    """
    æ ¹æ®æ—¶é—´æˆ³åŠ è½½æœ€ä½³æ¨¡å‹
    
    Args:
        model_type: æ¨¡å‹ç±»å‹å­—ç¬¦ä¸²
        timestamp: æ¨¡å‹æ—¶é—´æˆ³
        result_dir_path: resultç›®å½•è·¯å¾„ result/{timestamp}
        device: è®¾å¤‡
        hidden_size: æ¨¡å‹çš„éšè—å±‚å¤§å° (d_model)
    
    Returns:
        model: åŠ è½½æƒé‡åçš„æ¨¡å‹
    """
    # æ„å»ºcheckpointè·¯å¾„ï¼šresult/{timestamp}/checkpoints/best_model_{timestamp}.pth
    checkpoint_path = os.path.join(result_dir_path, 'checkpoints', f'best_model_{timestamp}.pth')
    
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {checkpoint_path}")
    
    # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    try:
        model = eval(model_type)(d_model=hidden_size).to(device)
    except (NameError, AttributeError) as e:
        raise ValueError(f"æ— æ³•åˆ›å»ºæ¨¡å‹ '{model_type}': {e}")
    
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # æ‰“å°åŠ è½½ä¿¡æ¯
    print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {checkpoint_path}")
    print(f"   æ¨¡å‹ç±»å‹={model_type}, d_model={hidden_size}")
    
    return model


def test(model, dataset, loss_fn, metrics_fn, device, threshold=0.5,
         show_progress=True, num_collect=None, batch_size=4):
    """
    åœ¨æ•°æ®é›†ä¸Šæµ‹è¯•æ¨¡å‹ï¼ˆéšæœºé‡‡æ ·æŒ‡å®šæ•°é‡æ ·æœ¬ï¼‰
    
    Args:
        model: æ¨¡å‹
        dataset: æ•°æ®é›†
        loss_fn: æŸå¤±å‡½æ•°
        metrics_fn: æŒ‡æ ‡è®¡ç®—å‡½æ•°
        device: è®¾å¤‡
        threshold: é˜ˆå€¼ï¼ˆç”¨äºæŸå¤±è®¡ç®—ï¼Œä¸å½±å“metrics_fnï¼Œmetrics_fnå†…éƒ¨ä¼šæ ¹æ®modeå¤„ç†ï¼‰
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        num_collect: æµ‹è¯•å’Œæ”¶é›†çš„æ ·æœ¬æ•°é‡ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ•°æ®
        batch_size: æ‰¹å¤„ç†å¤§å°
    
    Returns:
        avg_loss: å¹³å‡æŸå¤±
        metrics: æŒ‡æ ‡å­—å…¸
        sample_data: æ ·æœ¬æ•°æ®å­—å…¸
    """
    model.eval()
    total_samples = len(dataset)
    
    # ç¡®å®šæµ‹è¯•æ ·æœ¬æ•°é‡
    if num_collect is None:
        num_test = total_samples
        test_indices = list(range(total_samples))
        if show_progress:
            print(f"  ğŸ” æµ‹è¯•å…¨éƒ¨æ•°æ® ({num_test} ä¸ªæ ·æœ¬)...")
    else:
        num_test = min(num_collect, total_samples)
        test_indices = torch.randperm(total_samples)[:num_test].tolist()
        if show_progress:
            if num_collect > total_samples:
                print(f"  âš ï¸  è¯·æ±‚æ ·æœ¬æ•° {num_collect} è¶…è¿‡æ•°æ®é›†å¤§å° {total_samples}ï¼Œè°ƒæ•´ä¸º {num_test}")
            print(f"  ğŸ² éšæœºé‡‡æ · {num_test} ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•...")
    
    # æ”¶é›†æ•°æ®
    cmap_list = []
    thresholds_list = []
    mus_list = []
    
    for idx in test_indices:
        cmap_data, mu_count, threshold_data = dataset[idx]
        cmap_list.append(cmap_data)
        thresholds_list.append(threshold_data)
        mus_list.append(mu_count)
    
    # è½¬æ¢ä¸ºtensorï¼ˆCPUç«¯ï¼‰
    cmap_tensor = torch.stack(cmap_list)
    thresholds_tensor = torch.stack(thresholds_list)
    
    # åˆ†æ‰¹é¢„æµ‹ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
    total_loss = 0.0
    all_preds = []
    all_targets = []
    num_batches = (num_test + batch_size - 1) // batch_size
    
    with torch.no_grad():
        for i in range(0, num_test, batch_size):
            batch_end = min(i + batch_size, num_test)
            batch_cmap = cmap_tensor[i:batch_end].to(device)
            batch_thresholds = thresholds_tensor[i:batch_end].to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(batch_cmap)
            
            # è®¡ç®—æŸå¤±
            loss = loss_fn(outputs, batch_thresholds)
            total_loss += loss.item()
            
            # æ ¹æ®threshold_modeå†³å®šæ˜¯å¦äºŒå€¼åŒ–
            # æ³¨æ„ï¼šè¿™é‡Œpredsç”¨äºè®¡ç®—æŒ‡æ ‡ï¼Œmetrics_fnå†…éƒ¨ä¼šæ ¹æ®modeå‚æ•°å¤„ç†
            # å¯¹äºbinaryæ¨¡å¼ï¼Œmetrics_fnå†…éƒ¨ä¼šè¿›è¡ŒäºŒå€¼åŒ–ï¼›å¯¹äºvalueæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å€¼
            all_preds.append(outputs.cpu())
            all_targets.append(batch_thresholds.cpu())
            
            # æ‰“å°è¿›åº¦
            if show_progress and (i // batch_size + 1) % max(1, num_batches // 5) == 0:
                progress = (i + batch_size) / num_test * 100
                print(f"    ğŸ” æµ‹è¯•è¿›åº¦: {min(i + batch_size, num_test)}/{num_test} ({progress:.0f}%)")
    
    if show_progress:
        print(f"  âœ… æµ‹è¯•å®Œæˆ: {num_test} ä¸ªæ ·æœ¬")
    
    # æ‹¼æ¥æ‰€æœ‰æ‰¹æ¬¡
    all_preds = torch.cat(all_preds, dim=0)
    all_targets = torch.cat(all_targets, dim=0)
    
    # è®¡ç®—å¹³å‡æŸå¤±å’ŒæŒ‡æ ‡
    avg_loss = total_loss / num_batches
    metrics = metrics_fn(all_preds, all_targets)
    
    # ç»„è£…æ ·æœ¬æ•°æ®
    sample_data = {
        'indices': test_indices,
        'cmap': cmap_tensor.numpy(),
        'thresholds_true': thresholds_tensor.numpy(),
        'thresholds_pred': all_preds.numpy(),
        'mus_true': torch.stack(mus_list).numpy()
    }
    
    return avg_loss, metrics, sample_data


def save_test_data(test_loss, test_metrics, sample_data, timestamp, result_dir=None, save_samples=True, args=None, config=None):
    """ä¿å­˜æµ‹è¯•æ•°æ®"""
    print(f"\nğŸ“Š ä¿å­˜æµ‹è¯•æ•°æ®...")
    
    # ç»„è£…ä¿å­˜è·¯å¾„ï¼ˆä¿å­˜åˆ°result/{timestamp}/ç›®å½•ï¼‰
    if result_dir is None:
        result_dir = os.path.join('result', timestamp)
    os.makedirs(result_dir, exist_ok=True)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_data = {
        'timestamp': timestamp,
        'test_loss': float(test_loss),
        'test_metrics': {k: float(v) for k, v in test_metrics.items()},
        'num_samples': len(sample_data['indices'])
    }
    
    # æ·»åŠ argsé…ç½®ï¼ˆè½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼‰
    if args is not None:
        test_data['config_args'] = vars(args)
    
    # æ·»åŠ configé…ç½®ï¼ˆè½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼‰
    if config is not None:
        test_data['config'] = config.to_dict() if hasattr(config, 'to_dict') else config
    
    # å¦‚æœéœ€è¦ä¿å­˜æ ·æœ¬æ•°æ®ï¼Œæ·»åŠ åˆ° JSON
    if save_samples:
        test_data['sample_data'] = {
            'indices': sample_data['indices'],
            'cmap': sample_data['cmap'].tolist(),
            'thresholds_true': sample_data['thresholds_true'].tolist(),
            'thresholds_pred': sample_data['thresholds_pred'].tolist(),
            'mus_true': sample_data['mus_true'].tolist()
        }
    
    # ä¿å­˜ä¸º JSONï¼ˆä¿å­˜åˆ°result/{timestamp}/ç›®å½•ï¼‰
    test_data_path = os.path.join(result_dir, f'test_{timestamp}.json')
    with open(test_data_path, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æµ‹è¯•æ•°æ®å·²ä¿å­˜: {test_data_path}")


def main(args):
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # åŠ è½½é…ç½®
    config = get_config()
    
    print("=" * 50)
    print("ğŸ§ª MU Threshold Prediction - æ¨¡å‹æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    print("\nğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®é›†...")
    Dataset = eval(args.dataset_type)
    test_dataset = Dataset(
        config['SimDataset.data'], 
        args.dataset_type, 
        start_percent=0.95, 
        end_percent=1.0,
        stage='test',
        threshold_mode=args.threshold_mode
    )
    
    print(f"âœ… æµ‹è¯•é›†å¤§å°: {len(test_dataset)} ä¸ªæ ·æœ¬")
    
    # ç¡®å®šæ—¶é—´æˆ³å’Œresultç›®å½•
    timestamp = args.timestamp
    result_dir_path = os.path.join(args.result_dir, timestamp)
    checkpoints_dir = os.path.join(result_dir_path, 'checkpoints')
    
    # ç¡®ä¿resultç›®å½•å’Œcheckpointsç›®å½•å­˜åœ¨
    if not os.path.exists(result_dir_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°ç»“æœç›®å½•: {result_dir_path}ï¼Œè¯·æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦æ­£ç¡®")
    if not os.path.exists(checkpoints_dir):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°checkpointsç›®å½•: {checkpoints_dir}")
    
    print(f"\nğŸ“¥ ä½¿ç”¨æ—¶é—´æˆ³: {timestamp}")
    print(f"ğŸ“ ç»“æœç›®å½•: {result_dir_path}")
    print(f"ğŸ“ Checkpointsç›®å½•: {checkpoints_dir}")
    
    # åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹
    print(f"\nğŸ”§ åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹: {args.model_type}")
    model = load_best_model(args.model_type, timestamp, result_dir_path, args.device, args.hidden_size)
    
    # åˆ›å»ºæŸå¤±å‡½æ•°ï¼ˆæ”¯æŒåŠ æƒï¼‰
    if args.use_weighted_loss and args.loss_type == 'ce':
        pos_weight_tensor = torch.tensor(args.pos_weight, device=args.device)
        def loss_fn(pred, target):
            return ce(pred, target, pos_weight=pos_weight_tensor)
    else:
        loss_fn = eval(args.loss_type)
    
    # åˆ›å»ºæŒ‡æ ‡å‡½æ•°ï¼ˆä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼å’Œæ¨¡å¼ï¼‰
    def metrics_fn(pred, target):
        return b_v_metrics(pred, target, mode=args.threshold_mode, threshold=args.metrics_threshold)
    
    # æ‰§è¡Œæµ‹è¯•
    print("\nğŸ§ª æµ‹è¯•é˜¶æ®µ")
    test_loss, test_metrics, sample_data = test(
        model, test_dataset, loss_fn, metrics_fn, args.device,
        threshold=args.metrics_threshold,
        show_progress=True, 
        num_collect=args.num_collect if args.num_collect > 0 else None,
        batch_size=args.batch_size
    )
    
    # æ‰“å°æµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœ:")
    print("=" * 60)
    print(f"   Loss: {test_loss:.6f}")
    for metric_name, metric_value in test_metrics.items():
        print(f"   {metric_name}: {metric_value:.4f}")
    print("=" * 60)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    save_test_data(test_loss, test_metrics, sample_data, timestamp, result_dir=result_dir_path, save_samples=args.save_samples, args=args, config=config)


if __name__ == '__main__':
    parser = get_args_parser()
    args = parser.parse_args()
    main(args)
