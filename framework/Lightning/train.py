"""
PyTorch Lightning è®­ç»ƒå…¥å£è„šæœ¬
"""

import argparse
import os
import sys
import json
import warnings
from datetime import datetime
from pathlib import Path

import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from framework.Lightning.module import MUNEModule
from framework.Lightning.data_module import MUNEDataModule
from config import get_config
from utils import set_seed

# å¿½ç•¥ NVML è­¦å‘Š
warnings.filterwarnings('ignore', message='.*NVML.*')


def get_args_parser():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser('MU Threshold Prediction Training (Lightning)', add_help=False)
    
    # æ•°æ®ç›¸å…³
    parser.add_argument('--batch_size', default=32, type=int, help='Batch size for training')
    parser.add_argument('--num_workers', default=8, type=int, help='Number of data loading workers')
    parser.add_argument('--pin_memory', default=True, type=bool, help='Pin memory for data loading')
    parser.add_argument('--dataset_type', default='Sim', choices=['Sim', 'Real'], help='Dataset type')
    parser.add_argument('--threshold_mode', default='binary', choices=['value', 'binary'], 
                       help='Threshold output mode: binary=0/1 mask, value=actual threshold values')
    
    # è®­ç»ƒç›¸å…³
    parser.add_argument('--epochs', default=10, type=int, help='Number of training epochs')
    parser.add_argument('--device', default='cuda', type=str, help='Device to use (cpu/cuda)')
    parser.add_argument('--lr', default=5e-4, type=float, help='Learning rate')
    parser.add_argument('--weight_decay', default=1e-4, type=float, help='Weight decay (L2 regularization)')
    parser.add_argument('--grad_clip', default=1.0, type=float, help='Gradient clipping value (0=disabled)')
    parser.add_argument('--patience', default=20, type=int, help='Early stopping patience')
    
    # æ¨¡å‹ç›¸å…³
    parser.add_argument('--model_type', default='LSTM', 
                       choices=['Linear', 'CNN', 'LSTM', 'MUNECNN', 'Transformer'], 
                       help='Model architecture type')
    parser.add_argument('--d_model', default=128, type=int, 
                       help='Model hidden dimension (default: 128)')
    parser.add_argument('--dropout', default=0.1, type=float, 
                       help='Dropout rate for regularization (0.0-1.0)')
    
    # æŸå¤±å‡½æ•°ç›¸å…³
    parser.add_argument('--loss_type', default='emd', 
                       choices=['ce', 'weighted_bce', 'dice', 'iou', 'f1', 'count', 'emd', 'hamming',
                               'jaccard', 'tversky', 'focal_tversky', 'combo', 'mixed'],
                       help='Loss function type')
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    parser.add_argument('--lr_scheduler', default='plateau', 
                       choices=['none', 'cosine', 'plateau'], 
                       help='Learning rate scheduler type')
    parser.add_argument('--warmup_epochs', default=2, type=int, 
                       help='Warmup epochs for cosine scheduler')
    
    # æŒ‡æ ‡ç›¸å…³
    parser.add_argument('--metrics_threshold', default=0.65, type=float, 
                       help='Threshold for metrics calculation')
    
    # è¾“å‡ºç›¸å…³
    parser.add_argument('--result_dir', default='result', type=str, 
                       help='Root directory to save experiment results')
    parser.add_argument('--timestamp', default=None, type=str, 
                       help='Experiment timestamp (e.g., 20251023_123456). If not provided, auto-generate')
    parser.add_argument('--save_log', default=False, type=bool, 
                       help='Save console output to log file in result directory')

    # æ•°æ®åˆ’åˆ†
    parser.add_argument('--train_split', default=0.85, type=float,
                       help='Fraction of data used for training (0-1)')
    parser.add_argument('--val_split', default=0.95, type=float,
                       help='Fraction of data used for train+val (train <= val <=1)')
    
    # Lightningç›¸å…³
    parser.add_argument('--accelerator', default='gpu', type=str, 
                       help='Lightning accelerator (gpu, cpu, etc.)')
    parser.add_argument('--devices', default=1, type=int, 
                       help='Number of devices to use')
    parser.add_argument('--precision', default=32, type=int, 
                       choices=[16, 32], help='Training precision (16 or 32)')
    parser.add_argument('--enable_progress_bar', default=True, type=bool, 
                       help='Enable progress bar')
    
    return parser


def setup_log(result_dir, timestamp, enable=True):
    """
    è®¾ç½®æ—¥å¿—é‡å®šå‘ï¼šå°†æ§åˆ¶å°è¾“å‡ºåŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶
    
    Args:
        result_dir: ç»“æœç›®å½•è·¯å¾„
        timestamp: æ—¶é—´æˆ³
        enable: æ˜¯å¦å¯ç”¨é‡å®šå‘
    
    Returns:
        restore_func: æ¢å¤å‡½æ•°ï¼Œè°ƒç”¨åæ¢å¤æ ‡å‡†è¾“å‡ºå¹¶å…³é—­æ—¥å¿—æ–‡ä»¶
        log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæœªå¯ç”¨åˆ™è¿”å›None
    """
    log_file_path = os.path.join(result_dir, f'train_{timestamp}.log')
    
    if not enable:
        return lambda: None, None
    
    log_file_obj = open(log_file_path, 'w', encoding='utf-8')
    
    class Tee:
        def __init__(self, *files):
            self.files = files
        def write(self, obj):
            for f in self.files:
                f.write(obj)
                f.flush()
        def flush(self):
            for f in self.files:
                f.flush()
    
    original_stdout = sys.stdout
    original_stderr = sys.stderr
    sys.stdout = Tee(sys.stdout, log_file_obj)
    sys.stderr = Tee(sys.stderr, log_file_obj)
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file_path}")
    
    def restore():
        sys.stdout = original_stdout
        sys.stderr = original_stderr
        log_file_obj.close()
    
    return restore, log_file_path


def main(args):
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®éšæœºç§å­
    set_seed(57)
    
    # è·å–é…ç½®
    config = get_config()

    if not (0.0 < args.train_split < args.val_split <= 1.0):
        raise ValueError("train_split must be within (0, val_split) and val_split <= 1.0")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    if args.timestamp:
        timestamp = args.timestamp
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_dir = os.path.join(args.result_dir, timestamp)
    os.makedirs(result_dir, exist_ok=True)
    os.makedirs(os.path.join(result_dir, "checkpoints"), exist_ok=True)
    os.makedirs(os.path.join(result_dir, "train_visual"), exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—é‡å®šå‘
    restore, log_file_path = setup_log(result_dir, timestamp, enable=args.save_log)
    
    try:
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: {args.model_type} + {args.loss_type}")
        print(f"ğŸ“Š æ•°æ®é›†: {args.dataset_type} | Epochs: {args.epochs}")
        print(f"ğŸ’¾ ç»“æœç›®å½•: {result_dir}\n")
        
        # è·å–æ•°æ®è·¯å¾„
        data_path = config['SimDataset.data']
        
        # åˆ›å»ºæ•°æ®æ¨¡å—
        data_module = MUNEDataModule(
            data_path=data_path,
            dataset_type=args.dataset_type,
            batch_size=args.batch_size,
            num_workers=args.num_workers,
            pin_memory=args.pin_memory,
            threshold_mode=args.threshold_mode,
            train_split=args.train_split,
            val_split=args.val_split
        )
        
        # åˆ›å»ºæ¨¡å‹æ¨¡å—
        model_module = MUNEModule(
            model_type=args.model_type,
            d_model=args.d_model,
            dropout=args.dropout,
            loss_type=args.loss_type,
            lr=args.lr,
            weight_decay=args.weight_decay,
            grad_clip=args.grad_clip,
            lr_scheduler=args.lr_scheduler,
            warmup_epochs=args.warmup_epochs,
            threshold_mode=args.threshold_mode,
            metrics_threshold=args.metrics_threshold,
            visual_dir=os.path.join(result_dir, 'train_visual')
        )
        
        # é…ç½®å›è°ƒå‡½æ•°
        callbacks = []
        
        # æ¨¡å‹æ£€æŸ¥ç‚¹å›è°ƒ
        checkpoint_callback = ModelCheckpoint(
            dirpath=os.path.join(result_dir, "checkpoints"),
            filename=f'best_model_{timestamp}',
            monitor='val_loss',
            mode='min',
            save_top_k=1,
            save_last=True,
            verbose=True
        )
        callbacks.append(checkpoint_callback)
        
        # æ—©åœå›è°ƒ
        early_stop_callback = EarlyStopping(
            monitor='val_loss',
            mode='min',
            patience=args.patience,
            verbose=True
        )
        callbacks.append(early_stop_callback)
        
        # å­¦ä¹ ç‡ç›‘æ§å›è°ƒ
        lr_monitor = LearningRateMonitor(logging_interval='epoch')
        callbacks.append(lr_monitor)
        
        # é…ç½®æ—¥å¿—è®°å½•å™¨
        logger = TensorBoardLogger(
            save_dir=result_dir,
            name='lightning_logs',
            version=timestamp
        )
        
        # é…ç½®è®­ç»ƒå™¨
        trainer = pl.Trainer(
            max_epochs=args.epochs,
            accelerator=args.accelerator if args.device == 'cuda' else 'cpu',
            devices=args.devices if args.device == 'cuda' else 1,
            precision=args.precision,
            callbacks=callbacks,
            logger=logger,
            enable_progress_bar=args.enable_progress_bar,
            log_every_n_steps=10,
            check_val_every_n_epoch=1,
            gradient_clip_val=args.grad_clip if args.grad_clip > 0 else None,
        )
        
        # å¼€å§‹è®­ç»ƒ
        trainer.fit(model_module, data_module)
        
        # ä¿å­˜è®­ç»ƒé…ç½®å’Œç»“æœ
        print("\nğŸ“Š ä¿å­˜è®­ç»ƒæ•°æ®...")
        save_training_data(
            trainer=trainer,
            model_module=model_module,
            data_module=data_module,
            save_path=os.path.join(result_dir, f'train_{timestamp}.json'),
            timestamp=timestamp,
            best_model_path=checkpoint_callback.best_model_path,
            args=args,
            config=config
        )
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"   - æœ€ä½³æ¨¡å‹: {checkpoint_callback.best_model_path}")
        print(f"   - è®­ç»ƒæ•°æ®: {os.path.join(result_dir, f'train_{timestamp}.json')}")
        if args.save_log:
            print(f"   - æ—¥å¿—æ–‡ä»¶: {log_file_path}")
        
    finally:
        # æ¢å¤æ—¥å¿—é‡å®šå‘
        restore()


def save_training_data(trainer, model_module, data_module, save_path, timestamp, 
                      best_model_path, args=None, config=None):
    """ä¿å­˜è®­ç»ƒæ•°æ®ä¸ºJSONæ ¼å¼"""
    # ä» LightningModule ä¸­è·å–çœŸå®çš„è®­ç»ƒå†å²
    training_history = getattr(model_module, 'training_history', [])
    
    # å‡†å¤‡ä¿å­˜çš„æ•°æ®
    training_data = {
        'timestamp': timestamp,
        'total_epochs': trainer.current_epoch + 1,
        'best_model_path': best_model_path,
        'training_history': training_history,
        'framework': 'pytorch_lightning'
    }
    
    # æ·»åŠ argsé…ç½®
    if args is not None:
        training_data['config_args'] = vars(args)
    
    # æ·»åŠ configé…ç½®
    if config is not None:
        training_data['config'] = config.to_dict() if hasattr(config, 'to_dict') else config
    
    # ä¿å­˜ä¸ºJSON
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(training_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… è®­ç»ƒæ•°æ®å·²ä¿å­˜: {save_path}")


if __name__ == '__main__':
    parser = get_args_parser()
    args = parser.parse_args()
    main(args)

