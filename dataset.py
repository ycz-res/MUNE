from py_compile import main
import torch
import numpy as np
from torch.utils.data import Dataset
from typing import List, Tuple, Dict, Any
from utils import load_mat_data
import h5py
import os



class Sim(Dataset):
    """ä»¿çœŸæ•°æ®é›†ç±»"""
    
    def __init__(self, data_path: str, data_type: str = 'sim', start_percent: float = 0.0, 
                 end_percent: float = 1.0, stage: str = 'train', threshold_mode: str = 'binary'):
        self.data_path = data_path
        self.data_type = data_type
        self.start_percent = start_percent
        self.end_percent = end_percent
        self.stage = stage
        self.threshold_mode = threshold_mode
        
        if stage not in ['train', 'val', 'test']:
            raise ValueError("é˜¶æ®µæ ‡ç­¾å¿…é¡»æ˜¯ 'train', 'val', æˆ– 'test'")
        if not (0.0 <= start_percent <= 1.0 and 0.0 <= end_percent <= 1.0):
            raise ValueError("ç™¾åˆ†æ¯”å¿…é¡»åœ¨0.0åˆ°1.0ä¹‹é—´")
        if start_percent >= end_percent:
            raise ValueError("èµ·å§‹ç™¾åˆ†æ¯”å¿…é¡»å°äºç»“æŸç™¾åˆ†æ¯”")
        
        # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©åŠ è½½æ–¹æ³•
        self.data_dict = self.__load_data(self.data_type)
        
        # æå–æ•°æ®
        self.cmap_amplitudes = self.data_dict['data']       # (N, 500) - CMAPå¹…å€¼æ•°æ®
        self.mu_count_labels = self.data_dict['label_num'] # (N,) - è¿åŠ¨å•ä½æ•°é‡æ ‡ç­¾
        self.mu_thresholds = self.data_dict['muThr']  # (N, 500) - è¿åŠ¨å•ä½é˜ˆå€¼ä½ç½®
        
        # è®¡ç®—æ•°æ®èŒƒå›´
        self.total_samples = self.cmap_amplitudes.shape[0]
        self.start_idx = int(self.total_samples * start_percent)
        self.end_idx = int(self.total_samples * end_percent)
        self.num_samples = self.end_idx - self.start_idx
        
        print(f"æ•°æ®é›†ä¿¡æ¯ - å½“å‰é˜¶æ®µ: {self.stage}: æ€»æ ·æœ¬æ•°={self.total_samples}, "
              f"ä½¿ç”¨èŒƒå›´=[{self.start_idx}:{self.end_idx}], å®é™…æ ·æœ¬æ•°={self.num_samples}")
    
    def __load_data(self, data_type: str):
        if data_type == 'sim':
            return self.__load_sim_data()
        elif data_type == 'real':
            return self.__load_real_data()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")

    def __load_sim_data(self):
        """ä¸¥æ ¼åŠ è½½é¢„å¤„ç†åçš„æ•°æ®ï¼ˆ.npzï¼‰ï¼Œè‹¥ä¸å­˜åœ¨åˆ™æŠ¥é”™æç¤ºå…ˆè¿è¡Œé¢„å¤„ç†ã€‚"""

        # æ”¯æŒä¸¤ç§é»˜è®¤å‘½åï¼šdata.npzï¼ˆæ¨èï¼‰ä¸å†å² *_preprocessed_<mode>.npz
        base, _ = os.path.splitext(self.data_path)
        candidates = [
            os.path.join(os.path.dirname(self.data_path), "data.npz"),
            f"{base}_preprocessed_{self.threshold_mode}.npz",
        ]

        selected = None
        for p in candidates:
            if os.path.isfile(p):
                selected = p
                break

        if selected is not None:
            print(f"ğŸ“¦ æ£€æµ‹åˆ°é¢„å¤„ç†æ–‡ä»¶: {selected}ï¼Œç›´æ¥åŠ è½½ä»¥åŠ é€Ÿè®­ç»ƒ...")
            npz = np.load(selected, allow_pickle=True)
            cmap = np.array(npz["cmap"]).astype(np.float32)
            mus = np.array(npz["mus"]).astype(np.float32)
            thresholds = np.array(npz["thresholds"]).astype(np.float32)
            result = {"data": cmap, "label_num": mus, "muThr": thresholds}
            print(f"âœ… é¢„å¤„ç†æ•°æ®åŠ è½½å®Œæˆ: data={cmap.shape}, thresholds={thresholds.shape}")
            return result

        raise FileNotFoundError(
            f"æœªæ‰¾åˆ°é¢„å¤„ç†æ–‡ä»¶: {preprocessed_npz}ã€‚è¯·å…ˆè¿è¡Œé¢„å¤„ç†è„šæœ¬ç”Ÿæˆ .npz æ–‡ä»¶ã€‚"
        )
    
    

    def __load_real_data(self):
        return {}
    
    def __len__(self) -> int:
        return self.num_samples
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        è·å–å•ä¸ªæ ·æœ¬æ•°æ®ï¼ˆè‡ªåŠ¨é€‚é…å¤§æ–‡ä»¶æ‡’åŠ è½½ï¼‰
        
        Args:
            idx (int): æ ·æœ¬ç´¢å¼•ï¼ˆç›¸å¯¹äºå½“å‰æ•°æ®èŒƒå›´çš„ç´¢å¼•ï¼‰
        
        Returns:
            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
                - cmap_data: CMAPå¹…å€¼æ•°æ® (500,)
                - mu_count: è¿åŠ¨å•ä½æ•°é‡æ ‡ç­¾ (æ ‡é‡)
                - threshold_data: è¿åŠ¨å•ä½é˜ˆå€¼æ•°æ® (500,)
        """

        # éªŒè¯ç´¢å¼•èŒƒå›´
        if not (0 <= idx < self.num_samples):
            raise IndexError(f"ç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ [0, {self.num_samples})")

        # è½¬æ¢ä¸ºå…¨å±€ç´¢å¼•
        actual_idx = self.start_idx + idx

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤§æ–‡ä»¶ï¼ˆh5py.Datasetï¼‰
        if isinstance(self.data_dict["data"], h5py.Dataset):
            # ---- å¤§æ–‡ä»¶æ‡’åŠ è½½æ¨¡å¼ ----
            # ä» HDF5 æ•°æ®ä¸­è¯»å–å•ä¸ªæ ·æœ¬
            data_item = np.array(self.data_dict["data"][actual_idx])  # (500, 2)
            mu_count_val = np.array(self.data_dict["label_num"][actual_idx]).astype(np.float32)
            mu_thr_item = np.array(self.data_dict["muThr"][actual_idx]).astype(np.float32)

            # æå–ç”µæµ (x) ä¸ å¹…å€¼ (y)
            x = data_item[:, 0]
            y = data_item[:, 1]

            # å½’ä¸€åŒ–å¹…å€¼åˆ° [0,1]
            y = (y - y.min()) / (y.max() - y.min() + 1e-8)
            cmap_data = torch.from_numpy(y).float()

            # MUæ•°é‡æ ‡ç­¾
            mu_count = torch.tensor(mu_count_val, dtype=torch.float32)

            # é˜ˆå€¼æ•°æ®ï¼ˆ500ç»´æ˜ å°„ï¼‰
            threshold_data = torch.from_numpy(mu_thr_item).float()

        else:
            # ---- å°æ–‡ä»¶å†…å­˜æ¨¡å¼ ----
            cmap_data = torch.from_numpy(self.cmap_amplitudes[actual_idx, :]).float()
            mu_count = torch.tensor(self.mu_count_labels[actual_idx], dtype=torch.float32)
            threshold_data = torch.from_numpy(self.mu_thresholds[actual_idx, :]).float()

        return cmap_data, mu_count, threshold_data


    @staticmethod
    def collate_fn(batch: List[Tuple[torch.Tensor, torch.Tensor, torch.Tensor]]) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
        """
        æ‰¹å¤„ç†å‡½æ•°ï¼Œå°†å•ä¸ªæ ·æœ¬ç»„åˆæˆæ‰¹æ¬¡æ•°æ®
        
        Args:
            batch: åŒ…å«å¤šä¸ªæ ·æœ¬çš„åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬ä¸º(cmap_data, mu_count, threshold_data)
            
        Returns:
            Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
                - src: {"cmap": tensor} - CMAPæ•°æ®ï¼Œå½¢çŠ¶(batch_size, 500)
                - tgt: {"mus": tensor, "thresholds": tensor} - MUsæ•°é‡å’Œé˜ˆå€¼æ•°æ®
        """
        # è§£åŒ…æ‰¹æ¬¡æ•°æ®
        cmap_data_list, mu_counts_list, threshold_data_list = zip(*batch)
        
        # æ„å»ºsrc: {"cmap": tensor}æ ¼å¼
        src = {"cmap": torch.stack(cmap_data_list, dim=0)}  # (batch_size, 500) - CMAPæ•°æ®
        
        # æ„å»ºtgt: {"mus": tensor, "thresholds": tensor}æ ¼å¼
        tgt = {
            "mus": torch.stack(mu_counts_list, dim=0),           # (batch_size,)
            "thresholds": torch.stack(threshold_data_list, dim=0)  # (batch_size, 500)
        }
        
        return src, tgt

    # =====================================================
    # âœ… é™æ€æ–¹æ³•ï¼šé˜ˆå€¼é‡å¤æ£€æŸ¥ï¼ˆå®Œæ•´é€»è¾‘å°è£…ï¼‰
    # =====================================================
    @staticmethod
    def check_threshold_duplicates(data_path: str, tol: float = 1e-5, verbose: bool = True) -> list:
        """
        æ£€æŸ¥ä»¿çœŸæ•°æ®ä¸­çš„ MU é˜ˆå€¼æ˜¯å¦å­˜åœ¨é‡å¤æˆ–è¿‡è¿‘å€¼ã€‚
        Args:
            data_path (str): .mat æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆéœ€åŒ…å« 'label_thr' é”®ï¼‰
            tol (float): åˆ¤æ–­é‡å¤çš„å®¹å·®ï¼Œé»˜è®¤ 1e-5
            verbose (bool): æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            list: å«æœ‰é‡å¤é˜ˆå€¼çš„æ ·æœ¬ç´¢å¼•åˆ—è¡¨
        """
        try:
            mat_data = load_mat_data(data_path)
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥ï¼š{e}")
            return []

        if "label_thr" not in mat_data:
            print("âŒ æ•°æ®æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'label_thr' é”®ï¼Œæ— æ³•æ£€æµ‹ã€‚")
            return []

        muThr = np.array(mat_data["label_thr"]).squeeze()

        # ç¡®ä¿æ•°æ®ä¸ºäºŒç»´æ ¼å¼è¿›è¡Œå¤„ç†
        if muThr.ndim == 1:
            muThr = muThr.reshape(-1, 1)

        print(f"âœ… åŠ è½½æ•°æ®æˆåŠŸï¼š{muThr.shape[0]} ä¸ªæ ·æœ¬ï¼Œå¼€å§‹æ£€æµ‹é‡å¤é˜ˆå€¼...\n")

        N = muThr.shape[0]
        dup_samples = []

        for n in range(N):
            vals = muThr[n][muThr[n] > 0]
            if len(vals) <= 1:
                continue
            vals_sorted = np.sort(vals)
            diffs = np.diff(vals_sorted)
            if np.any(diffs < tol):
                dup_samples.append(n)
                if verbose:
                    dup_vals = vals_sorted[np.where(diffs < tol)[0]]
                    print(f"âš ï¸ æ ·æœ¬ {n} å­˜åœ¨é‡å¤æˆ–è¿‡è¿‘é˜ˆå€¼: {dup_vals}")

        if verbose:
            if len(dup_samples) == 0:
                print("âœ… æ‰€æœ‰æ ·æœ¬é˜ˆå€¼å‡å”¯ä¸€ï¼Œæ— é‡å¤ã€‚")
            else:
                print(f"\nâš ï¸ å…± {len(dup_samples)} ä¸ªæ ·æœ¬å­˜åœ¨é‡å¤é˜ˆå€¼: {dup_samples}\n")

        print("â€”â€” æ£€æŸ¥å®Œæˆ â€”â€”")
        if len(dup_samples) == 0:
            print("âœ… æ•°æ®é€šè¿‡å®Œæ•´æ€§æ£€æŸ¥ï¼Œå¯å®‰å…¨è¿›å…¥è®­ç»ƒé˜¶æ®µã€‚\n")
        else:
            print("âš ï¸ è¯·æ£€æŸ¥ä¸Šæ–¹è¾“å‡ºï¼Œå»ºè®®æ‰‹åŠ¨æˆ–è„šæœ¬ä¿®å¤é‡å¤é˜ˆå€¼ã€‚\n")

        return dup_samples


if __name__ == "__main__":
    """
    - æ£€æŸ¥ä»¿çœŸæ•°æ®ä¸­çš„è¿åŠ¨å•ä½(MU)é˜ˆå€¼æ˜¯å¦å­˜åœ¨é‡å¤æˆ–è¿‡è¿‘çš„å€¼
    """
    Sim.check_threshold_duplicates(
        data_path="./data/SimDataset/data.mat",  # æ•°æ®è·¯å¾„
        tol=1e-5,                        # å®¹å·®
        verbose=True                     # æ‰“å°è¯¦æƒ…
    )