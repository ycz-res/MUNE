"""
è®­ç»ƒæ¨¡å—
åŒ…å«è®­ç»ƒå¾ªç¯ã€éªŒè¯ã€æ¨¡å‹ä¿å­˜ç­‰åŠŸèƒ½
"""

from torch.utils.data import DataLoader
import torch
import torch.optim as optim
import torch.nn as nn
import argparse
import os
from datetime import datetime
import numpy as np

from dataset import SimDataset
from config import get_config
from model import LinearModel
from loss import thr_loss, focal_thr_loss
from visualization import MUThresholdVisualizer
from utils import set_seed
from metrics import mu_threshold_metrics, comprehensive_metrics, print_metrics_summary


def get_args_parser():
    a_parser = argparse.ArgumentParser('MU Threshold Prediction Training', add_help=False)
    a_parser.add_argument('--batch_size', default=4, type=int, help='Batch size for training')
    a_parser.add_argument('--epochs', default=20, type=int, help='Number of training epochs')
    a_parser.add_argument('--shuffle', default=True, type=bool, help='Shuffle training data')
    a_parser.add_argument('--num_workers', default=0, type=int, help='Number of data loading workers')
    a_parser.add_argument('--pin_memory', default=False, type=bool, help='Pin memory for data loading')
    a_parser.add_argument('--device', default='cpu', type=str, help='Device to use (cpu/cuda)')
    
    # æ–°å¢å‚æ•°
    a_parser.add_argument('--lr', default=1e-5, type=float, help='Learning rate')
    a_parser.add_argument('--weight_decay', default=1e-3, type=float, help='Weight decay')
    a_parser.add_argument('--patience', default=5, type=int, help='Early stopping patience')
    a_parser.add_argument('--loss_type', default='thr', choices=['thr', 'focal'], help='Loss function type')
    a_parser.add_argument('--save_best', default=True, type=bool, help='Save best model')
    a_parser.add_argument('--save_dir', default='checkpoints', type=str, help='Directory to save models')

    return a_parser

def main(args):
    # è®¾ç½®éšæœºç§å­
    set_seed(57)
    
    config = get_config()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    curves_dir = f"plot/training_curves_{timestamp}"
    os.makedirs(curves_dir, exist_ok=True)
    os.makedirs(args.save_dir, exist_ok=True)
    print(f"è®­ç»ƒæ›²çº¿å°†ä¿å­˜åˆ°: {curves_dir}")
    print(f"æ¨¡å‹å°†ä¿å­˜åˆ°: {args.save_dir}")
    
    print("=== åŠ è½½æ•°æ®é›† ===")
    # ä½¿ç”¨åŒä¸€ä¸ªæ•°æ®æ–‡ä»¶çš„ä¸åŒç™¾åˆ†æ¯”èŒƒå›´ï¼Œå¹¶æŒ‡å®šé˜¶æ®µæ ‡ç­¾
    train_dataset = SimDataset(config['SimDataset.data'], 'sim', start_percent=0.0, end_percent=0.05, stage='train')
    val_dataset = SimDataset(config['SimDataset.data'], 'sim', start_percent=0.05, end_percent=0.1, stage='val')
    test_dataset = SimDataset(config['SimDataset.data'], 'sim', start_percent=0.1, end_percent=0.15, stage='test')
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, 
                             collate_fn=SimDataset.collate_fn, num_workers=args.num_workers, 
                             pin_memory=args.pin_memory)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, 
                           collate_fn=SimDataset.collate_fn, num_workers=args.num_workers, 
                           pin_memory=args.pin_memory)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, 
                            collate_fn=SimDataset.collate_fn, num_workers=args.num_workers, 
                            pin_memory=args.pin_memory)

    print("=== åˆå§‹åŒ–æ¨¡å‹ ===")
    model = LinearModel(d_model=64)
    model.to(args.device)

    optimizer = optim.AdamW(model.parameters(), lr=args.lr, betas=(0.9, 0.95), weight_decay=args.weight_decay)
    
    # é€‰æ‹©æŸå¤±å‡½æ•°
    if args.loss_type == 'focal':
        criterion = focal_thr_loss
        print("ä½¿ç”¨ Focal Loss")
    else:
        criterion = thr_loss
        print("ä½¿ç”¨æ ‡å‡†é˜ˆå€¼æŸå¤±")
    
    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    visualizer = MUThresholdVisualizer(curves_dir)
    
    # æ—©åœæœºåˆ¶
    best_score = -float('inf')
    best_epoch = 0
    patience_counter = 0
    
    print(f"=== å¼€å§‹è®­ç»ƒï¼Œå…± {args.epochs} ä¸ªepoch ===")
    
    for epoch in range(args.epochs):
        # è®­ç»ƒä¸€ä¸ªepoch
        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, args.device, epoch, args.epochs)
        
        # éªŒè¯ä¸€ä¸ªepoch
        val_result = validate_one_epoch(model, val_loader, criterion, args.device, epoch, args.epochs)
        if isinstance(val_result, tuple):
            val_loss, val_metrics = val_result
        else:
            val_loss = val_result
            val_metrics = None
        
        # æ›´æ–°å¯è§†åŒ–å™¨
        visualizer.update_epoch(epoch + 1, train_loss, val_loss)
        
        # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜
        if val_metrics and val_metrics['score'] > best_score:
            best_score = val_metrics['score']
            best_epoch = epoch + 1
            patience_counter = 0
            print(f"  ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹! ç»¼åˆåˆ†æ•°: {best_score:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if args.save_best:
                model_path = os.path.join(args.save_dir, f'best_model_{timestamp}.pth')
                torch.save({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_score': best_score,
                    'val_metrics': val_metrics
                }, model_path)
                print(f"  ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        else:
            patience_counter += 1
        
        # æ—©åœæ£€æŸ¥
        if patience_counter >= args.patience:
            print(f"  â¹ï¸ æ—©åœè§¦å‘! è¿ç»­ {args.patience} ä¸ªepochæ— æ”¹å–„")
            break
        
        print("-" * 50)
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹åœ¨ç¬¬ {best_epoch} ä¸ªepochï¼Œç»¼åˆåˆ†æ•°: {best_score:.4f}")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•
    if args.save_best and os.path.exists(os.path.join(args.save_dir, f'best_model_{timestamp}.pth')):
        checkpoint = torch.load(os.path.join(args.save_dir, f'best_model_{timestamp}.pth'))
        model.load_state_dict(checkpoint['model_state_dict'])
        print("å·²åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•")
    
    print("=== æµ‹è¯•é˜¶æ®µ ===")
    avg_test_loss = test_one_epoch(model, test_loader, criterion, args.device, visualizer)
    print(f"æµ‹è¯•å®Œæˆ, å¹³å‡æŸå¤±: {avg_test_loss:.6f}")
    
    # ç”Ÿæˆç»¼åˆè®­ç»ƒåˆ†ææŠ¥å‘Š
    model_info = {
        "æ¨¡å‹ç±»å‹": "LinearModel",
        "éšè—ç»´åº¦": 64,
        "ä¼˜åŒ–å™¨": "AdamW",
        "å­¦ä¹ ç‡": args.lr,
        "æƒé‡è¡°å‡": args.weight_decay,
        "æŸå¤±å‡½æ•°": args.loss_type,
        "æ—©åœè€å¿ƒ": args.patience
    }
    
    dataset_info = {
        "è®­ç»ƒæ ·æœ¬æ•°": len(train_dataset),
        "éªŒè¯æ ·æœ¬æ•°": len(val_dataset),
        "æµ‹è¯•æ ·æœ¬æ•°": len(test_dataset),
        "æ‰¹æ¬¡å¤§å°": args.batch_size
    }
    
    visualizer.generate_comprehensive_report(
        test_loss=avg_test_loss,
        model_info=model_info,
        dataset_info=dataset_info
    )
    print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {curves_dir}")


def train_one_epoch(model, train_loader, optimizer, criterion, device, epoch, total_epochs):
    model.train()
    total_loss = 0.0
    batch_count = 0
    
    for batch_idx, batch in enumerate(train_loader):
        src, tgt = batch
        # ç§»åŠ¨åˆ°è®¾å¤‡
        src = {key: value.to(device) for key, value in src.items()}
        tgt = {key: value.to(device) for key, value in tgt.items()}
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        thresholds_pred = model(src["cmap"])  # æ¨¡å‹åªè¾“å‡ºé˜ˆå€¼é¢„æµ‹
        
        # è®¡ç®—æŸå¤±
        loss = criterion(thresholds_pred, tgt["thresholds"])
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        batch_count += 1
        
        if batch_idx % 10 == 0:
            print(f"Epoch {epoch+1}/{total_epochs}, Batch {batch_idx}, Loss: {loss.item():.6f}")
    
    avg_loss = total_loss / batch_count
    print(f"Epoch {epoch+1}/{total_epochs} è®­ç»ƒå®Œæˆ, å¹³å‡æŸå¤±: {avg_loss:.6f}")
    return avg_loss


def validate_one_epoch(model, val_loader, criterion, device, epoch, total_epochs):
    model.eval()
    val_loss = 0.0
    val_batch_count = 0
    
    # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®å€¼ç”¨äºè®¡ç®—æŒ‡æ ‡
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(val_loader):
            src, tgt = batch
            # ç§»åŠ¨åˆ°è®¾å¤‡
            src = {key: value.to(device) for key, value in src.items()}
            tgt = {key: value.to(device) for key, value in tgt.items()}
            
            thresholds_pred = model(src["cmap"])  # æ¨¡å‹åªè¾“å‡ºé˜ˆå€¼é¢„æµ‹
            loss = criterion(thresholds_pred, tgt["thresholds"])
            
            val_loss += loss.item()
            val_batch_count += 1
            
            # æ”¶é›†é¢„æµ‹å’ŒçœŸå®å€¼
            all_predictions.append(thresholds_pred)
            all_targets.append(tgt["thresholds"])
    
    # è®¡ç®—éªŒè¯æŒ‡æ ‡
    if all_predictions:
        all_pred = torch.cat(all_predictions, dim=0)
        all_true = torch.cat(all_targets, dim=0)
        
        # ä½¿ç”¨ç»¼åˆè¯„ä»·æŒ‡æ ‡
        val_metrics = comprehensive_metrics(all_pred, all_true)
        
        avg_val_loss = val_loss / val_batch_count
        print(f"Epoch {epoch+1}/{total_epochs} éªŒè¯å®Œæˆ, å¹³å‡æŸå¤±: {avg_val_loss:.6f}")
        print(f"  éªŒè¯æŒ‡æ ‡ - æ•°é‡å‡†ç¡®ç‡: {val_metrics['count_accuracy']:.4f}, "
              f"ä½ç½®IoU: {val_metrics['pos_iou']:.4f}, "
              f"ä½ç½®F1: {val_metrics['pos_f1']:.4f}, "
              f"æ•°å€¼MAE: {val_metrics['val_mae']:.4f}, "
              f"ç»¼åˆåˆ†æ•°: {val_metrics['composite_score']:.4f}")
        return avg_val_loss, val_metrics
    else:
        avg_val_loss = val_loss / val_batch_count
        print(f"Epoch {epoch+1}/{total_epochs} éªŒè¯å®Œæˆ, å¹³å‡æŸå¤±: {avg_val_loss:.6f}")
        return avg_val_loss, None


def test_one_epoch(model, test_loader, criterion, device, visualizer):
    model.eval()
    test_loss = 0.0
    test_batch_count = 0
    
    # æ”¶é›†é¢„æµ‹ç»Ÿè®¡æ•°æ®
    all_predicted_mu_counts = []
    all_true_mu_counts = []
    all_predicted_threshold_counts = []
    all_true_threshold_counts = []
    
    # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®å€¼ç”¨äºè®¡ç®—æŒ‡æ ‡
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(test_loader):
            src, tgt = batch
            # ç§»åŠ¨åˆ°è®¾å¤‡
            src = {key: value.to(device) for key, value in src.items()}
            tgt = {key: value.to(device) for key, value in tgt.items()}
            
            thresholds_pred = model(src["cmap"])  # æ¨¡å‹åªè¾“å‡ºé˜ˆå€¼é¢„æµ‹
            loss = criterion(thresholds_pred, tgt["thresholds"])
            
            test_loss += loss.item()
            test_batch_count += 1
            
            # æ”¶é›†é¢„æµ‹å’ŒçœŸå®å€¼ç”¨äºæŒ‡æ ‡è®¡ç®—
            all_predictions.append(thresholds_pred)
            all_targets.append(tgt["thresholds"])
            
            # æ”¶é›†é¢„æµ‹ç»Ÿè®¡æ•°æ®
            true_mu_counts = tgt['mus'].cpu().numpy().astype(int).tolist()
            true_threshold_counts = (tgt['thresholds'] != 0).sum(dim=1).cpu().numpy().astype(int).tolist()
            predicted_threshold_counts = (thresholds_pred != 0).sum(dim=1).cpu().numpy().astype(int).tolist()
            
            # ä»é˜ˆå€¼é¢„æµ‹ä¸­æ¨æ–­MUæ•°é‡ï¼ˆç®€åŒ–æ–¹æ³•ï¼šå‡è®¾æ¯ä¸ªé˜ˆå€¼å¯¹åº”ä¸€ä¸ªMUï¼‰
            predicted_mu_counts = predicted_threshold_counts
            
            all_predicted_mu_counts.extend(predicted_mu_counts)
            all_true_mu_counts.extend(true_mu_counts)
            all_predicted_threshold_counts.extend(predicted_threshold_counts)
            all_true_threshold_counts.extend(true_threshold_counts)
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªé¢„æµ‹ç»“æœ
            if batch_idx < 3:
                print(f"æµ‹è¯•æ‰¹æ¬¡ {batch_idx+1}:")
                print(f"  çœŸå®MUæ•°é‡: {true_mu_counts}")
                print(f"  çœŸå®é˜ˆå€¼æ•°é‡: {true_threshold_counts}")
                print(f"  é¢„æµ‹é˜ˆå€¼æ•°é‡: {predicted_threshold_counts}")
                print(f"  æŸå¤±: {loss.item():.6f}")
    
    # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
    if all_predictions:
        all_pred = torch.cat(all_predictions, dim=0)
        all_true = torch.cat(all_targets, dim=0)
        test_metrics = comprehensive_metrics(all_pred, all_true)
        
        # ä½¿ç”¨æ–°çš„æŒ‡æ ‡æ‰“å°å‡½æ•°
        print_metrics_summary(test_metrics, "æµ‹è¯•é˜¶æ®µ")
    
    # æ›´æ–°å¯è§†åŒ–å™¨çš„é¢„æµ‹ç»Ÿè®¡æ•°æ®
    visualizer.update_prediction_stats(
        all_predicted_mu_counts, all_true_mu_counts,
        all_predicted_threshold_counts, all_true_threshold_counts
    )
    
    avg_test_loss = test_loss / test_batch_count
    return avg_test_loss



if __name__ == '__main__':
    parser = get_args_parser()
    args = parser.parse_args()
    main(args)

