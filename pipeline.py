"""
å®Œæ•´çš„è®­ç»ƒ-æµ‹è¯•-å¯è§†åŒ–-é€šçŸ¥ Pipeline
"""

import os
import sys
import shutil
import subprocess
import json
import glob
import time
import requests
from datetime import datetime
import argparse


class TrainingPipeline:
    """è®­ç»ƒæµç¨‹ç®¡ç†å™¨"""
    
    def __init__(self, 
                 epochs=150,
                 use_weighted_loss=True,
                 pos_weight=50.0,
                 metrics_threshold=0.5,
                 feishu_webhook=None,
                 clean_old_data=True):
        """
        åˆå§‹åŒ– Pipeline
        
        Args:
            epochs: è®­ç»ƒè½®æ•°
            use_weighted_loss: æ˜¯å¦ä½¿ç”¨åŠ æƒæŸå¤±
            pos_weight: æ­£æ ·æœ¬æƒé‡
            metrics_threshold: æŒ‡æ ‡è®¡ç®—é˜ˆå€¼
            feishu_webhook: é£ä¹¦ webhook URL
            clean_old_data: æ˜¯å¦æ¸…ç†æ—§æ•°æ®
        """
        self.epochs = epochs
        self.use_weighted_loss = use_weighted_loss
        self.pos_weight = pos_weight
        self.metrics_threshold = metrics_threshold
        self.feishu_webhook = feishu_webhook
        self.clean_old_data = clean_old_data
        
        self.timestamp = None
        self.train_time = 0
        self.test_time = 0
        
    def log(self, message):
        """æ‰“å°å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—"""
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}")
        
    def clean_directories(self):
        """æ¸…ç©ºæ—§æ•°æ®"""
        if not self.clean_old_data:
            self.log("è·³è¿‡æ¸…ç†æ—§æ•°æ®")
            return
            
        self.log("å¼€å§‹æ¸…ç†æ—§æ•°æ®...")
        
        # æ¸…ç©º curve_data
        curve_data_dir = 'plot/curve_data'
        if os.path.exists(curve_data_dir):
            for file in os.listdir(curve_data_dir):
                file_path = os.path.join(curve_data_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
                    self.log(f"  åˆ é™¤: {file_path}")
        
        # æ¸…ç©º visual_res
        visual_res_dir = 'plot/visual_res'
        if os.path.exists(visual_res_dir):
            shutil.rmtree(visual_res_dir)
            self.log(f"  åˆ é™¤ç›®å½•: {visual_res_dir}")
        
        self.log("âœ… æ¸…ç†å®Œæˆ")
        
    def run_train(self):
        """è¿è¡Œè®­ç»ƒ"""
        self.log("="*60)
        self.log("å¼€å§‹è®­ç»ƒ...")
        self.log("="*60)
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            'python3', 'train.py',
            '--epochs', str(self.epochs),
            '--metrics_threshold', str(self.metrics_threshold)
        ]
        
        if self.use_weighted_loss:
            cmd.extend(['--use_weighted_loss', 'True'])
            cmd.extend(['--pos_weight', str(self.pos_weight)])
        
        self.log(f"è®­ç»ƒå‘½ä»¤: {' '.join(cmd)}")
        
        # è¿è¡Œè®­ç»ƒ
        start_time = time.time()
        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            self.train_time = time.time() - start_time
            self.log(f"âœ… è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {self.train_time/60:.2f} åˆ†é’Ÿ")
            
            # ä»è¾“å‡ºä¸­æå–æ—¶é—´æˆ³
            output = result.stdout
            for line in output.split('\n'):
                if 'best_model_' in line and '.pth' in line:
                    # æå–æ—¶é—´æˆ³
                    import re
                    match = re.search(r'best_model_(\d{8}_\d{6})\.pth', line)
                    if match:
                        self.timestamp = match.group(1)
                        self.log(f"ğŸ“… è®­ç»ƒæ—¶é—´æˆ³: {self.timestamp}")
                        break
            
            if not self.timestamp:
                # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä»æ–‡ä»¶ç³»ç»Ÿè·å–æœ€æ–°çš„
                self.timestamp = self.get_latest_timestamp()
                self.log(f"ğŸ“… è‡ªåŠ¨è·å–æ—¶é—´æˆ³: {self.timestamp}")
                
        except subprocess.CalledProcessError as e:
            self.log(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            self.log(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            raise
            
    def get_latest_timestamp(self):
        """è·å–æœ€æ–°çš„æ—¶é—´æˆ³"""
        checkpoint_files = glob.glob('checkpoints/best_model_*.pth')
        if not checkpoint_files:
            raise FileNotFoundError("æœªæ‰¾åˆ°ä»»ä½• checkpoint æ–‡ä»¶")
        
        latest = max(checkpoint_files, key=os.path.getmtime)
        timestamp = os.path.basename(latest).replace('best_model_', '').replace('.pth', '')
        return timestamp
        
    def run_test(self):
        """è¿è¡Œæµ‹è¯•"""
        self.log("="*60)
        self.log("å¼€å§‹æµ‹è¯•...")
        self.log("="*60)
        
        cmd = [
            'python3', 'test.py',
            '--timestamp', self.timestamp,
            '--metrics_threshold', str(self.metrics_threshold)
        ]
        
        self.log(f"æµ‹è¯•å‘½ä»¤: {' '.join(cmd)}")
        
        start_time = time.time()
        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            self.test_time = time.time() - start_time
            self.log(f"âœ… æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {self.test_time:.2f} ç§’")
        except subprocess.CalledProcessError as e:
            self.log(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            self.log(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            raise
            
    def run_visualization(self):
        """è¿è¡Œå¯è§†åŒ–"""
        self.log("="*60)
        self.log("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        self.log("="*60)
        
        cmd = [
            'python3', 'plot/visualization.py',
            '--timestamp', self.timestamp
        ]
        
        self.log(f"å¯è§†åŒ–å‘½ä»¤: {' '.join(cmd)}")
        
        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            self.log("âœ… å¯è§†åŒ–å®Œæˆ")
        except subprocess.CalledProcessError as e:
            self.log(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
            self.log(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            raise
            
    def send_to_feishu(self):
        """å‘é€ç»“æœåˆ°é£ä¹¦"""
        if not self.feishu_webhook:
            self.log("âš ï¸  æœªé…ç½®é£ä¹¦ webhookï¼Œè·³è¿‡é€šçŸ¥")
            return
            
        self.log("="*60)
        self.log("å‘é€ç»“æœåˆ°é£ä¹¦...")
        self.log("="*60)
        
        # è¯»å–è®­ç»ƒå’Œæµ‹è¯•ç»“æœ
        train_json = f'plot/curve_data/train_{self.timestamp}.json'
        test_json = f'plot/curve_data/test_{self.timestamp}.json'
        
        train_data = {}
        test_data = {}
        
        if os.path.exists(train_json):
            with open(train_json, 'r') as f:
                train_data = json.load(f)
        
        if os.path.exists(test_json):
            with open(test_json, 'r') as f:
                test_data = json.load(f)
        
        # å‡†å¤‡æ–‡æœ¬æ¶ˆæ¯
        message = self.prepare_feishu_message(train_data, test_data)
        
        # å‘é€æ–‡æœ¬æ¶ˆæ¯
        self.send_feishu_text(message)
        
        # å‘é€å›¾ç‰‡
        image_files = [
            'plot/visual_res/loss_curves.png',
            'plot/visual_res/val_metrics_curves.png',
            'plot/visual_res/test_metrics_summary.png',
            'plot/visual_res/random_test_samples.png'
        ]
        
        for img_path in image_files:
            if os.path.exists(img_path):
                self.send_feishu_image(img_path)
            else:
                self.log(f"âš ï¸  å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
        
        self.log("âœ… é£ä¹¦é€šçŸ¥å‘é€å®Œæˆ")
        
    def prepare_feishu_message(self, train_data, test_data):
        """å‡†å¤‡é£ä¹¦æ¶ˆæ¯å†…å®¹"""
        # è·å–æœ€ç»ˆæŒ‡æ ‡
        if train_data and 'training_history' in train_data:
            last_epoch = train_data['training_history'][-1]
            train_loss = last_epoch.get('train_loss', 0)
            val_loss = last_epoch.get('val_loss', 0)
            val_metrics = last_epoch.get('val_metrics', {})
        else:
            train_loss = val_loss = 0
            val_metrics = {}
        
        if test_data and 'test_metrics' in test_data:
            test_loss = test_data.get('test_loss', 0)
            test_metrics = test_data.get('test_metrics', {})
        else:
            test_loss = 0
            test_metrics = {}
        
        message = f"""ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆé€šçŸ¥

ğŸ“… æ—¶é—´æˆ³: {self.timestamp}
â±ï¸  è®­ç»ƒè€—æ—¶: {self.train_time/60:.2f} åˆ†é’Ÿ
ğŸ”¢ è®­ç»ƒè½®æ•°: {self.epochs}

ğŸ“Š è®­ç»ƒç»“æœ:
â€¢ è®­ç»ƒæŸå¤±: {train_loss:.6f}
â€¢ éªŒè¯æŸå¤±: {val_loss:.6f}
â€¢ Precision: {val_metrics.get('Precision', 0):.4f}
â€¢ Recall: {val_metrics.get('Recall', 0):.4f}
â€¢ F1: {val_metrics.get('F1', 0):.4f}
â€¢ IoU: {val_metrics.get('IoU', 0):.4f}

ğŸ§ª æµ‹è¯•ç»“æœ:
â€¢ æµ‹è¯•æŸå¤±: {test_loss:.6f}
â€¢ Precision: {test_metrics.get('Precision', 0):.4f}
â€¢ Recall: {test_metrics.get('Recall', 0):.4f}
â€¢ F1: {test_metrics.get('F1', 0):.4f}
â€¢ IoU: {test_metrics.get('IoU', 0):.4f}

ğŸ“ æ–‡ä»¶ä½ç½®:
â€¢ æ¨¡å‹: checkpoints/best_model_{self.timestamp}.pth
â€¢ è®­ç»ƒæ•°æ®: plot/curve_data/train_{self.timestamp}.json
â€¢ æµ‹è¯•æ•°æ®: plot/curve_data/test_{self.timestamp}.json
â€¢ å¯è§†åŒ–: plot/visual_res/
"""
        return message
        
    def send_feishu_text(self, text):
        """å‘é€æ–‡æœ¬æ¶ˆæ¯åˆ°é£ä¹¦"""
        payload = {
            "msg_type": "text",
            "content": {
                "text": text
            }
        }
        
        try:
            response = requests.post(self.feishu_webhook, json=payload)
            response.raise_for_status()
            self.log("âœ… æ–‡æœ¬æ¶ˆæ¯å‘é€æˆåŠŸ")
        except Exception as e:
            self.log(f"âŒ å‘é€æ–‡æœ¬æ¶ˆæ¯å¤±è´¥: {e}")
            
    def send_feishu_image(self, image_path):
        """å‘é€å›¾ç‰‡åˆ°é£ä¹¦"""
        # é£ä¹¦éœ€è¦å…ˆä¸Šä¼ å›¾ç‰‡è·å– image_keyï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        # å®é™…ä½¿ç”¨æ—¶éœ€è¦å…ˆè°ƒç”¨é£ä¹¦ API ä¸Šä¼ å›¾ç‰‡
        self.log(f"ğŸ“· å‘é€å›¾ç‰‡: {image_path}")
        
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®ç°é£ä¹¦å›¾ç‰‡ä¸Šä¼ çš„å®Œæ•´æµç¨‹
        # 1. ä¸Šä¼ å›¾ç‰‡åˆ°é£ä¹¦è·å– image_key
        # 2. ä½¿ç”¨ image_key å‘é€å›¾ç‰‡æ¶ˆæ¯
        # å…·ä½“å®ç°éœ€è¦é£ä¹¦çš„ app_id å’Œ app_secret
        
        # è¿™é‡Œä»…å‘é€æ–‡æœ¬æç¤º
        text = f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨: {os.path.basename(image_path)}"
        payload = {
            "msg_type": "text",
            "content": {
                "text": text
            }
        }
        
        try:
            response = requests.post(self.feishu_webhook, json=payload)
            response.raise_for_status()
        except Exception as e:
            self.log(f"âŒ å‘é€å›¾ç‰‡æç¤ºå¤±è´¥: {e}")
            
    def run(self):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        start_time = time.time()
        
        try:
            # 1. æ¸…ç†æ—§æ•°æ®
            if self.clean_old_data:
                self.clean_directories()
            
            # 2. è®­ç»ƒ
            self.run_train()
            
            # 3. æµ‹è¯•
            self.run_test()
            
            # 4. å¯è§†åŒ–
            self.run_visualization()
            
            # 5. å‘é€åˆ°é£ä¹¦
            self.send_to_feishu()
            
            total_time = time.time() - start_time
            
            self.log("="*60)
            self.log(f"ğŸ‰ Pipeline å®Œæˆ! æ€»è€—æ—¶: {total_time/60:.2f} åˆ†é’Ÿ")
            self.log("="*60)
            
        except Exception as e:
            self.log(f"âŒ Pipeline å¤±è´¥: {e}")
            raise


def main():
    parser = argparse.ArgumentParser('Training Pipeline')
    parser.add_argument('--epochs', type=int, default=150, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--use_weighted_loss', type=bool, default=True, help='ä½¿ç”¨åŠ æƒæŸå¤±')
    parser.add_argument('--pos_weight', type=float, default=50.0, help='æ­£æ ·æœ¬æƒé‡')
    parser.add_argument('--metrics_threshold', type=float, default=0.5, help='æŒ‡æ ‡è®¡ç®—é˜ˆå€¼')
    parser.add_argument('--feishu_webhook', type=str, default=None, help='é£ä¹¦ webhook URL')
    parser.add_argument('--clean', type=bool, default=True, help='æ˜¯å¦æ¸…ç†æ—§æ•°æ®')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¹¶è¿è¡Œ pipeline
    pipeline = TrainingPipeline(
        epochs=args.epochs,
        use_weighted_loss=args.use_weighted_loss,
        pos_weight=args.pos_weight,
        metrics_threshold=args.metrics_threshold,
        feishu_webhook=args.feishu_webhook,
        clean_old_data=args.clean
    )
    
    pipeline.run()


if __name__ == '__main__':
    main()

