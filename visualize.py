"""
MUé˜ˆå€¼é¢„æµ‹ä»»åŠ¡å¯è§†åŒ–æ¨¡å—
æ”¯æŒä»JSONæ•°æ®ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
"""

import os
import json
import matplotlib.pyplot as plt
import numpy as np
import argparse
from typing import Dict, List, Optional
import warnings
import torch

# å±è”½ä¸­æ–‡å­—ä½“è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, message='.*Glyph.*missing from font.*')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œç§‘ç ”é£æ ¼å…¨å±€å‚æ•°
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
# ç§‘ç ”é£æ ¼å…¨å±€è®¾ç½®
matplotlib.rcParams['font.size'] = 11
matplotlib.rcParams['axes.labelsize'] = 12
matplotlib.rcParams['axes.titlesize'] = 13
matplotlib.rcParams['xtick.labelsize'] = 10
matplotlib.rcParams['ytick.labelsize'] = 10
matplotlib.rcParams['legend.fontsize'] = 10
matplotlib.rcParams['figure.titlesize'] = 14
matplotlib.rcParams['axes.linewidth'] = 1.0
matplotlib.rcParams['grid.linewidth'] = 0.5
matplotlib.rcParams['grid.alpha'] = 0.3

# ç§‘ç ”é…è‰²æ–¹æ¡ˆï¼ˆä¸“ä¸šã€æ¸…æ™°ï¼‰
RESEARCH_COLORS = {
    'blue': '#2E5C8A',      # æ·±è“è‰²
    'light_blue': '#5B9BD5', # æµ…è“è‰²
    'green': '#70AD47',     # ç»¿è‰²
    'light_green': '#92D050', # æµ…ç»¿è‰²
    'orange': '#ED7D31',    # æ©™è‰²
    'light_orange': '#FFC000', # æµ…æ©™è‰²
    'red': '#C55A11',       # æ·±çº¢è‰²
    'light_red': '#E74C3C', # æµ…çº¢è‰²
    'purple': '#7030A0',    # ç´«è‰²
    'light_purple': '#9B59B6', # æµ…ç´«è‰²
    'gray': '#808080',      # ç°è‰²
    'dark_gray': '#505050', # æ·±ç°è‰²
}

# Hatchæ¨¡å¼ï¼ˆç”¨äºæ¡å½¢å›¾ï¼Œå¸¦é¢œè‰²çš„æ–œçº¿å¡«å……ï¼‰
HATCH_PATTERNS = ['/', '\\', '|', '-', '+', 'x', 'o', 'O', '.', '*']


def load_train_data(train_json_path: str) -> Dict:
    """åŠ è½½è®­ç»ƒæ•°æ®"""
    with open(train_json_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_test_data(test_json_path: str) -> Dict:
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    with open(test_json_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def plot_single_sample(src, thresholds_pred, thresholds_true, save_path, epoch=None, sample_idx=0, threshold=None):
    """
    ç»˜åˆ¶å•ä¸ªè®­ç»ƒæ ·æœ¬çš„å¯è§†åŒ–å›¾
    
    Args:
        src: è¾“å…¥æ•°æ®å­—å…¸ï¼ŒåŒ…å« 'cmap' é”®
        thresholds_pred: é¢„æµ‹çš„é˜ˆå€¼ logits (tensor, shape: [batch_size, seq_len])
        thresholds_true: çœŸå®çš„é˜ˆå€¼ (tensor, shape: [batch_size, seq_len])
        save_path: ä¿å­˜è·¯å¾„
        epoch: epochç¼–å·ï¼ˆå¯é€‰ï¼Œç”¨äºæ ‡é¢˜ï¼‰
        sample_idx: è¦å¯è§†åŒ–çš„æ ·æœ¬ç´¢å¼•ï¼ˆé»˜è®¤0ï¼Œå³ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
        threshold: ç”¨äºäºŒå€¼åŒ–çš„é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰ï¼Œå°† logits é€šè¿‡ sigmoid åä¸æ­¤é˜ˆå€¼æ¯”è¾ƒ
    """
    # æå–ç¬¬ä¸€ä¸ªæ ·æœ¬
    cmap = src["cmap"][sample_idx].detach().cpu().numpy() if torch.is_tensor(src["cmap"]) else src["cmap"][sample_idx]
    thresholds_pred_sample = thresholds_pred[sample_idx].detach().cpu() if torch.is_tensor(thresholds_pred) else thresholds_pred[sample_idx]
    thresholds_true_sample = thresholds_true[sample_idx].detach().cpu() if torch.is_tensor(thresholds_true) else thresholds_true[sample_idx]
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    if torch.is_tensor(thresholds_pred_sample):
        thresholds_pred_sample = thresholds_pred_sample.numpy()
    if torch.is_tensor(thresholds_true_sample):
        thresholds_true_sample = thresholds_true_sample.numpy()
    
    # ä½¿ç”¨é˜ˆå€¼ï¼ˆå¦‚æœæœªæä¾›ï¼Œä½¿ç”¨é»˜è®¤å€¼0.5ï¼‰
    if threshold is None:
        threshold = 0.5
    
    # è®¡ç®—é¢„æµ‹æ¦‚ç‡ï¼ˆåªè®¡ç®—ä¸€æ¬¡ï¼‰
    if isinstance(thresholds_pred_sample, np.ndarray):
        pred_probs = torch.sigmoid(torch.from_numpy(thresholds_pred_sample)).numpy()
    else:
        pred_probs = torch.sigmoid(thresholds_pred_sample).numpy() if torch.is_tensor(thresholds_pred_sample) else thresholds_pred_sample
    
    # ä½¿ç”¨thresholdé˜ˆå€¼è¿›è¡ŒäºŒå€¼åŒ–
    pred_binary = pred_probs > threshold
    
    # è®¡ç®—MUæ•°é‡ï¼ˆä½¿ç”¨thresholdé˜ˆå€¼ï¼‰
    mu_true = int((thresholds_true_sample > 0).sum())
    mu_pred = int(pred_binary.sum())
    
    # åˆ›å»ºå›¾å½¢
    fig, ax = plt.subplots(figsize=(12, 6))
    
    x_positions = np.arange(len(cmap))
    
    # ç»˜åˆ¶ CMAP (æ•£ç‚¹å›¾)
    ax.scatter(x_positions, cmap, c=RESEARCH_COLORS['light_blue'], s=1, alpha=0.3, label='CMAP')
    
    # è®¡ç®—ä½ç½®ï¼ˆä½¿ç”¨thresholdé˜ˆå€¼ï¼‰
    true_pos = set(np.where(thresholds_true_sample > 0)[0].tolist())
    pred_pos = set(np.where(pred_binary)[0].tolist())
    
    match_pos = sorted(true_pos & pred_pos)
    true_only_pos = sorted(true_pos - pred_pos)
    pred_only_pos = sorted(pred_pos - true_pos)
    
    # ç»˜åˆ¶åŒ¹é…çš„é˜ˆå€¼ (ç»¿è‰²)
    for p in match_pos:
        ax.axvline(x=p, color=RESEARCH_COLORS['green'], linestyle='-', linewidth=1.5, alpha=0.9)
    
    # ç»˜åˆ¶çœŸå®ä½†æœªé¢„æµ‹çš„ (è“è‰²è™šçº¿)
    for p in true_only_pos:
        ax.axvline(x=p, color=RESEARCH_COLORS['blue'], linestyle='--', linewidth=1.2, alpha=0.9)
    
    # ç»˜åˆ¶é¢„æµ‹ä½†ä¸çœŸå®çš„ (æ©™è‰²)
    for p in pred_only_pos:
        ax.axvline(x=p, color=RESEARCH_COLORS['orange'], linestyle='-', linewidth=1.2, alpha=0.9)
    
    # è®¾ç½®æ ‡é¢˜ï¼ˆæ˜¾ç¤ºé˜ˆå€¼ä¿¡æ¯ï¼‰
    title = f'Epoch {epoch} Training Sample | True MU: {mu_true} | Pred MU({threshold}): {mu_pred}' if epoch else f'Sample {sample_idx} | True MU: {mu_true} | Pred MU({threshold}): {mu_pred}'
    ax.set_title(title, fontsize=12, fontweight='bold')
    
    ax.set_xlim(0, len(cmap) - 1)
    ax.set_ylim(0, 1.1)
    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)
    ax.set_xlabel('Position', fontsize=11)
    ax.set_ylabel('Amplitude', fontsize=11)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    
    # æ·»åŠ å›¾ä¾‹
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor=RESEARCH_COLORS['green'], label='Match (True & Pred)'),
        Patch(facecolor=RESEARCH_COLORS['blue'], label='True Only (Miss)'),
        Patch(facecolor=RESEARCH_COLORS['orange'], label='Pred Only (False Alarm)')
    ]
    ax.legend(handles=legend_elements, loc='upper right', fontsize=10, framealpha=0.9, edgecolor='black')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def plot_loss_curves(train_data: Dict, save_dir: str):
    """ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿ï¼ˆæ”¯æŒå¤šä¸ªæŸå¤±åˆ†é‡ï¼‰"""
    history = train_data['training_history']
    epochs = [h['epoch'] for h in history]
    
    # æå–æ€»æŸå¤±ï¼ˆæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
    if 'train_loss_result' in history[0]:
        train_losses = [h['train_loss_result']['total'] for h in history]
        val_losses = [h['val_loss_result']['total'] for h in history]
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæŸå¤±åˆ†é‡
        first_train_losses = history[0]['train_loss_result'].get('losses', {})
        first_val_losses = history[0]['val_loss_result'].get('losses', {})
    else:
        # æ—§æ ¼å¼å…¼å®¹
        train_losses = [h['train_loss'] for h in history]
        val_losses = [h['val_loss'] for h in history]
        first_train_losses = {}
        first_val_losses = {}
    
    has_individual_losses = bool(first_train_losses or first_val_losses)
    
    if has_individual_losses:
        # å¦‚æœæœ‰å¤šä¸ªæŸå¤±åˆ†é‡ï¼Œåˆ›å»ºå­å›¾ï¼ˆå…±äº«xè½´ï¼Œä¼˜åŒ–é—´è·å’Œæ¯”ä¾‹ï¼‰
        fig, axes = plt.subplots(2, 1, figsize=(13, 10), sharex=True)
        fig.subplots_adjust(hspace=0.25, top=0.96, bottom=0.08, left=0.1, right=0.95)
        
        # ä¸Šå›¾ï¼šæ€»æŸå¤±
        ax1 = axes[0]
        # ä½¿ç”¨ç§‘ç ”é…è‰²
        ax1.plot(epochs, train_losses, color=RESEARCH_COLORS['blue'], marker='o', label='Train Total Loss', 
                markersize=4, linewidth=2.5, alpha=0.85, markevery=max(1, len(epochs)//25), 
                markerfacecolor='white', markeredgewidth=1.2, markeredgecolor=RESEARCH_COLORS['blue'])
        ax1.plot(epochs, val_losses, color=RESEARCH_COLORS['red'], marker='s', label='Val Total Loss', 
                markersize=4, linewidth=2.5, alpha=0.85, markevery=max(1, len(epochs)//25),
                markerfacecolor='white', markeredgewidth=1.2, markeredgecolor=RESEARCH_COLORS['red'])
        ax1.set_ylabel('Total Loss', fontsize=12, fontweight='bold')
        ax1.set_title('Total Loss: Training vs Validation', fontsize=13, fontweight='bold', pad=10)
        ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
        ax1.legend(fontsize=10, loc='upper right', framealpha=0.9, edgecolor='black', 
                  fancybox=False, shadow=False, frameon=True)
        ax1.tick_params(axis='both', labelsize=10)
        ax1.spines['top'].set_visible(False)
        ax1.spines['right'].set_visible(False)
        ax1.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
        ax1.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
        
        # ä¸‹å›¾ï¼šå„ä¸ªæŸå¤±åˆ†é‡
        ax2 = axes[1]
        # æ”¶é›†æ‰€æœ‰æŸå¤±åç§°ï¼ˆä»trainå’Œvalä¸­å–å¹¶é›†ï¼‰
        all_loss_names = set()
        for h in history:
            if 'train_loss_result' in h:
                all_loss_names.update(h['train_loss_result'].get('losses', {}).keys())
                all_loss_names.update(h['val_loss_result'].get('losses', {}).keys())
        all_loss_names = sorted(list(all_loss_names))
        
        # ä¸ºæ¯ä¸ªæŸå¤±åˆ†é‡åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨ç§‘ç ”é…è‰²æ–¹æ¡ˆï¼‰
        color_map = {
            'ce': RESEARCH_COLORS['blue'],
            'dice': RESEARCH_COLORS['orange'],
            'iou': RESEARCH_COLORS['green'],
            'focal': RESEARCH_COLORS['red'],
            'bce': RESEARCH_COLORS['purple'],
            'weighted_bce': RESEARCH_COLORS['light_orange'],
        }
        # å¦‚æœæŸå¤±åç§°ä¸åœ¨æ˜ å°„ä¸­ï¼Œä½¿ç”¨ç§‘ç ”é£æ ¼çš„æ¸å˜è‰²
        default_colors = [RESEARCH_COLORS['light_blue'], RESEARCH_COLORS['light_green'], 
                         RESEARCH_COLORS['light_purple'], RESEARCH_COLORS['gray']]
        colors = [color_map.get(name, default_colors[i % len(default_colors)]) 
                 for i, name in enumerate(all_loss_names)]
        
        # ç»˜åˆ¶è®­ç»ƒæŸå¤±åˆ†é‡ï¼ˆå®çº¿ï¼Œåœ†å½¢æ ‡è®°ï¼‰
        for loss_name, color in zip(all_loss_names, colors):
            train_loss_values = []
            for h in history:
                if 'train_loss_result' in h:
                    train_loss_values.append(h['train_loss_result'].get('losses', {}).get(loss_name, None))
                else:
                    train_loss_values.append(None)
            # è¿‡æ»¤æ‰Noneå€¼
            valid_indices = [i for i, v in enumerate(train_loss_values) if v is not None]
            if valid_indices:
                valid_epochs = [epochs[i] for i in valid_indices]
                valid_values = [train_loss_values[i] for i in valid_indices]
                ax2.plot(valid_epochs, valid_values, color=color, marker='o', 
                        label=f'Train {loss_name.upper()}', markersize=3.5, linewidth=2.0, 
                        linestyle='-', alpha=0.85, markevery=max(1, len(valid_epochs)//20),
                        markerfacecolor='white', markeredgewidth=1.0, markeredgecolor=color)
        
        # ç»˜åˆ¶éªŒè¯æŸå¤±åˆ†é‡ï¼ˆè™šçº¿ï¼Œæ–¹å½¢æ ‡è®°ï¼‰
        for loss_name, color in zip(all_loss_names, colors):
            val_loss_values = []
            for h in history:
                if 'val_loss_result' in h:
                    val_loss_values.append(h['val_loss_result'].get('losses', {}).get(loss_name, None))
                else:
                    val_loss_values.append(None)
            # è¿‡æ»¤æ‰Noneå€¼
            valid_indices = [i for i, v in enumerate(val_loss_values) if v is not None]
            if valid_indices:
                valid_epochs = [epochs[i] for i in valid_indices]
                valid_values = [val_loss_values[i] for i in valid_indices]
                ax2.plot(valid_epochs, valid_values, color=color, marker='s', 
                        label=f'Val {loss_name.upper()}', markersize=3.5, linewidth=2.0, 
                        linestyle='--', alpha=0.85, markevery=max(1, len(valid_epochs)//20),
                        markerfacecolor='white', markeredgewidth=1.0, markeredgecolor=color)
        
        ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Individual Loss', fontsize=12, fontweight='bold')
        ax2.set_title('Individual Loss Components: Training vs Validation', fontsize=13, fontweight='bold', pad=10)
        ax2.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
        ax2.legend(fontsize=9, loc='upper right', ncol=2, framealpha=0.9, 
                  edgecolor='black', fancybox=False, shadow=False, frameon=True, columnspacing=0.8)
        ax2.tick_params(axis='both', labelsize=10)
        ax2.spines['top'].set_visible(False)
        ax2.spines['right'].set_visible(False)
        ax2.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
        ax2.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
        
        plt.tight_layout()
        out_path = os.path.join(save_dir, 'loss_curves.png')
        plt.savefig(out_path, dpi=300, bbox_inches='tight')
        plt.close()
    else:
        # å¦‚æœæ²¡æœ‰å¤šä¸ªæŸå¤±åˆ†é‡ï¼Œåªç»˜åˆ¶æ€»æŸå¤±
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(epochs, train_losses, color=RESEARCH_COLORS['blue'], marker='o', 
               label='Train Loss', markersize=4, linewidth=2.5, alpha=0.85,
               markerfacecolor='white', markeredgewidth=1.2, markeredgecolor=RESEARCH_COLORS['blue'])
        ax.plot(epochs, val_losses, color=RESEARCH_COLORS['red'], marker='s', 
               label='Val Loss', markersize=4, linewidth=2.5, alpha=0.85,
               markerfacecolor='white', markeredgewidth=1.2, markeredgecolor=RESEARCH_COLORS['red'])
        ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')
        ax.set_ylabel('Loss', fontsize=12, fontweight='bold')
        ax.set_title('Training vs Validation Loss', fontsize=13, fontweight='bold')
        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
        ax.legend(fontsize=10, framealpha=0.9, edgecolor='black')
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
        ax.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
        plt.tight_layout()
        
        out_path = os.path.join(save_dir, 'loss_curves.png')
        plt.savefig(out_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    print(f"âœ… ä¿å­˜æŸå¤±æ›²çº¿: {os.path.join(save_dir, 'loss_curves.png')}")


def plot_val_metrics_curves(train_data: Dict, save_dir: str):
    """ç»˜åˆ¶éªŒè¯æŒ‡æ ‡æ›²çº¿"""
    history = train_data['training_history']
    epochs = [h['epoch'] for h in history]
    
    metrics_names = ['Precision', 'Recall', 'F1', 'IoU', 'EMD', 'Score']
    colors = [RESEARCH_COLORS['blue'], RESEARCH_COLORS['green'], RESEARCH_COLORS['red'], 
              RESEARCH_COLORS['purple'], RESEARCH_COLORS['orange'], RESEARCH_COLORS['light_orange']]
    markers = ['o', 's', '^', 'D', 'v', 'p']
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    for metric, color, marker in zip(metrics_names, colors, markers):
        values = [h['val_metrics'].get(metric, 0.0) for h in history]
        ax.plot(epochs, values, color=color, marker=marker, label=metric, 
                markersize=4, linewidth=2.0, alpha=0.85, markevery=max(1, len(epochs)//30),
                markerfacecolor='white', markeredgewidth=1.0, markeredgecolor=color)
    
    ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')
    ax.set_ylabel('Metric Value', fontsize=12, fontweight='bold')
    ax.set_title('Validation Metrics Over Epochs', fontsize=13, fontweight='bold')
    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
    ax.legend(fontsize=10, loc='best', framealpha=0.9, edgecolor='black', ncol=3)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
    ax.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
    plt.tight_layout()
    
    out_path = os.path.join(save_dir, 'val_metrics_curves.png')
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜éªŒè¯æŒ‡æ ‡æ›²çº¿: {out_path}")


def plot_test_metrics_summary(test_data: Dict, save_dir: str):
    """ç»˜åˆ¶æµ‹è¯•æŒ‡æ ‡æŸ±çŠ¶å›¾ï¼ˆæ”¯æŒå¤šä¸ªæŸå¤±åˆ†é‡ï¼‰"""
    # æ”¯æŒæ–°çš„æŸå¤±æ ¼å¼
    test_loss_result = test_data.get('test_loss_result', {})
    if test_loss_result:
        test_loss = test_loss_result.get('total', test_data.get('test_loss', 0.0))
        test_losses = test_loss_result.get('losses', {})
    else:
        test_loss = test_data.get('test_loss', 0.0)
        test_losses = {}
    
    test_metrics = test_data['test_metrics']
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæŸå¤±åˆ†é‡
    has_individual_losses = bool(test_losses)
    
    if has_individual_losses:
        # å¦‚æœæœ‰å¤šä¸ªæŸå¤±åˆ†é‡ï¼Œåˆ›å»ºä¸Šä¸‹å­å›¾ï¼ˆæŸå¤±åœ¨ä¸Šï¼ŒæŒ‡æ ‡åœ¨ä¸‹ï¼‰
        fig, axes = plt.subplots(2, 1, figsize=(12, 10))
        
        # ä¸Šå›¾ï¼šæŸå¤±ï¼ˆæ€»æŸå¤±å’Œå„ä¸ªåˆ†é‡ï¼‰
        ax1 = axes[0]
        loss_labels = ['Total Loss'] + [f'{k} Loss' for k in sorted(test_losses.keys())]
        loss_values = [test_loss] + [test_losses[k] for k in sorted(test_losses.keys())]
        loss_colors = [RESEARCH_COLORS['blue']] + [
            RESEARCH_COLORS['green'], RESEARCH_COLORS['orange'], RESEARCH_COLORS['red'],
            RESEARCH_COLORS['purple'], RESEARCH_COLORS['light_orange'], RESEARCH_COLORS['gray']
        ][:len(test_losses)]
        
        x1 = np.arange(len(loss_labels))
        bars1 = ax1.bar(x1, loss_values, color=loss_colors, alpha=0.7, edgecolor='black', 
                       linewidth=1.2, hatch=[HATCH_PATTERNS[i % len(HATCH_PATTERNS)] for i in range(len(loss_labels))])
        ax1.set_xticks(x1)
        ax1.set_xticklabels(loss_labels, fontsize=11, rotation=15, ha='right')
        ax1.set_ylabel('Loss Value', fontsize=12, fontweight='bold')
        ax1.set_title('Test Loss Components', fontsize=13, fontweight='bold')
        ax1.grid(True, axis='y', alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
        ax1.spines['top'].set_visible(False)
        ax1.spines['right'].set_visible(False)
        ax1.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
        ax1.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
        for bar, val in zip(bars1, loss_values):
            ax1.text(bar.get_x() + bar.get_width()/2, val, f'{val:.4f}', 
                    ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        # ä¸‹å›¾ï¼šå…¶ä»–æŒ‡æ ‡
        ax2 = axes[1]
        metric_labels = ['Precision', 'Recall', 'F1', 'IoU', 'EMD', 'Score']
        metric_values = [
            test_metrics['Precision'],
            test_metrics['Recall'],
            test_metrics['F1'],
            test_metrics['IoU'],
            test_metrics.get('EMD', 0.0),
            test_metrics['Score']
        ]
        metric_colors = [RESEARCH_COLORS['green'], RESEARCH_COLORS['orange'], RESEARCH_COLORS['red'],
                        RESEARCH_COLORS['purple'], RESEARCH_COLORS['light_orange'], RESEARCH_COLORS['blue']]
        
        x2 = np.arange(len(metric_labels))
        bars2 = ax2.bar(x2, metric_values, color=metric_colors, alpha=0.7, edgecolor='black', 
                       linewidth=1.2, hatch=[HATCH_PATTERNS[i % len(HATCH_PATTERNS)] for i in range(len(metric_labels))])
        ax2.set_xticks(x2)
        ax2.set_xticklabels(metric_labels, fontsize=11, rotation=15, ha='right')
        ax2.set_ylabel('Value', fontsize=12, fontweight='bold')
        ax2.set_title('Test Metrics', fontsize=13, fontweight='bold')
        ax2.grid(True, axis='y', alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
        ax2.spines['top'].set_visible(False)
        ax2.spines['right'].set_visible(False)
        ax2.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
        ax2.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
        for bar, val in zip(bars2, metric_values):
            ax2.text(bar.get_x() + bar.get_width()/2, val, f'{val:.4f}', 
                    ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        fig.suptitle('Test Metrics Summary', fontsize=14, fontweight='bold')
        plt.tight_layout()
    else:
        # å¦‚æœæ²¡æœ‰å¤šä¸ªæŸå¤±åˆ†é‡ï¼Œåªç»˜åˆ¶æ€»æŸå¤±å’Œå…¶ä»–æŒ‡æ ‡
        labels = ['Loss', 'Precision', 'Recall', 'F1', 'IoU', 'EMD', 'Score']
        values = [
            test_loss,
            test_metrics['Precision'],
            test_metrics['Recall'],
            test_metrics['F1'],
            test_metrics['IoU'],
            test_metrics.get('EMD', 0.0),
            test_metrics['Score']
        ]
        
        colors = [RESEARCH_COLORS['blue'], RESEARCH_COLORS['green'], RESEARCH_COLORS['orange'],
                 RESEARCH_COLORS['red'], RESEARCH_COLORS['purple'], RESEARCH_COLORS['light_orange'], RESEARCH_COLORS['gray']]
        
        fig, ax = plt.subplots(figsize=(12, 6))
        x = np.arange(len(labels))
        bars = ax.bar(x, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.2,
                     hatch=[HATCH_PATTERNS[i % len(HATCH_PATTERNS)] for i in range(len(labels))])
        
        ax.set_xticks(x)
        ax.set_xticklabels(labels, fontsize=11, rotation=15, ha='right')
        ax.set_ylabel('Value', fontsize=12, fontweight='bold')
        ax.set_title('Test Metrics Summary', fontsize=13, fontweight='bold')
        ax.grid(True, axis='y', alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
        ax.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
        for i, (bar, val) in enumerate(zip(bars, values)):
            ax.text(bar.get_x() + bar.get_width()/2, val, f'{val:.4f}', 
                    ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        plt.tight_layout()
    
    out_path = os.path.join(save_dir, 'test_metrics_summary.png')
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜æµ‹è¯•æŒ‡æ ‡æ±‡æ€»: {out_path}")


def plot_random_test_samples(test_data: Dict, save_dir: str, max_samples: int = 20):
    """ç»˜åˆ¶éšæœºæµ‹è¯•æ ·æœ¬çš„é˜ˆå€¼é¢„æµ‹å¯¹æ¯”å›¾"""
    if 'sample_data' not in test_data or not test_data['sample_data']:
        print("âš ï¸  æ²¡æœ‰æ ·æœ¬æ•°æ®ï¼Œè·³è¿‡æ ·æœ¬å¯è§†åŒ–")
        return
    
    sample_data = test_data['sample_data']
    indices = sample_data['indices']
    cmap_data = np.array(sample_data['cmap'])
    thr_true = np.array(sample_data['thresholds_true'])
    thr_pred = np.array(sample_data['thresholds_pred'])
    mus_true = np.array(sample_data['mus_true'])
    
    # ä»æµ‹è¯•æ•°æ®é…ç½®ä¸­è·å–é˜ˆå€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    threshold = 0.5  # é»˜è®¤é˜ˆå€¼
    if 'config_args' in test_data and test_data['config_args']:
        threshold = test_data['config_args'].get('metrics_threshold', 0.5)
    
    # é™åˆ¶æ ·æœ¬æ•°é‡
    num_samples = min(len(indices), max_samples)
    
    # è®¡ç®—å­å›¾å¸ƒå±€
    cols = 5
    rows = int(np.ceil(num_samples / cols))
    
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3))
    if rows == 1 and cols == 1:
        axes = np.array([[axes]])
    elif rows == 1:
        axes = axes.reshape(1, -1)
    elif cols == 1:
        axes = axes.reshape(-1, 1)
    
    fig.suptitle(f'Random Test Samples: True vs Predicted Thresholds (threshold={threshold})', 
                 fontsize=16, fontweight='bold')
    
    x_positions = np.arange(500)
    
    for i in range(num_samples):
        row = i // cols
        col = i % cols
        ax = axes[row, col]
        
        # è·å–æ•°æ®
        idx = indices[i]
        cmap_sample = cmap_data[i]
        thr_true_sample = thr_true[i]
        thr_pred_sample = thr_pred[i]
        mu_true = mus_true[i]
        
        # ç»˜åˆ¶ CMAP (æ•£ç‚¹å›¾)
        ax.scatter(x_positions, cmap_sample, c=RESEARCH_COLORS['light_blue'], s=1, alpha=0.3, label='CMAP')
        
        # å°†é¢„æµ‹çš„ logits è½¬æ¢ä¸ºæ¦‚ç‡å¹¶äºŒå€¼åŒ–
        pred_probs = torch.sigmoid(torch.from_numpy(thr_pred_sample)).numpy()
        pred_binary = pred_probs > threshold
        
        # è®¡ç®—ä½ç½®
        true_pos = set(np.where(thr_true_sample > 0)[0].tolist())
        pred_pos = set(np.where(pred_binary)[0].tolist())
        
        match_pos = sorted(true_pos & pred_pos)
        true_only_pos = sorted(true_pos - pred_pos)
        pred_only_pos = sorted(pred_pos - true_pos)
        
        # ç»˜åˆ¶åŒ¹é…çš„é˜ˆå€¼ (ç»¿è‰²)
        for p in match_pos:
            ax.axvline(x=p, color=RESEARCH_COLORS['green'], linestyle='-', linewidth=1.5, alpha=0.9)
        
        # ç»˜åˆ¶çœŸå®ä½†æœªé¢„æµ‹çš„ (è“è‰²è™šçº¿)
        for p in true_only_pos:
            ax.axvline(x=p, color=RESEARCH_COLORS['blue'], linestyle='--', linewidth=1.2, alpha=0.9)
        
        # ç»˜åˆ¶é¢„æµ‹ä½†ä¸çœŸå®çš„ (æ©™è‰²)
        for p in pred_only_pos:
            ax.axvline(x=p, color=RESEARCH_COLORS['orange'], linestyle='-', linewidth=1.2, alpha=0.9)
        
        # è®¡ç®—é¢„æµ‹çš„ MU æ•°é‡ï¼ˆä½¿ç”¨äºŒå€¼åŒ–åçš„ç»“æœï¼‰
        pred_mu = int(pred_binary.sum())
        
        ax.set_title(f'Sample {idx} | True MU: {mu_true} | Pred MU({threshold}): {pred_mu}', 
                    fontsize=9, fontweight='bold')
        ax.set_xlim(0, 499)
        ax.set_ylim(0, 1.1)
        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)
        ax.set_xlabel('Position', fontsize=9)
        ax.set_ylabel('Amplitude', fontsize=9)
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
    
    # éšè—å¤šä½™çš„å­å›¾
    total_plots = rows * cols
    for k in range(num_samples, total_plots):
        row = k // cols
        col = k % cols
        axes[row, col].axis('off')
    
    # æ·»åŠ å›¾ä¾‹
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor=RESEARCH_COLORS['green'], label='Match (True & Pred)'),
        Patch(facecolor=RESEARCH_COLORS['blue'], label='True Only (Miss)'),
        Patch(facecolor=RESEARCH_COLORS['orange'], label='Pred Only (False Alarm)')
    ]
    fig.legend(handles=legend_elements, loc='lower center', 
              bbox_to_anchor=(0.5, -0.01), ncol=3, fontsize=10, frameon=True, 
              framealpha=0.9, edgecolor='black')
    
    plt.tight_layout(rect=[0, 0.02, 1, 0.97])
    out_path = os.path.join(save_dir, 'random_test_samples.png')
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜æµ‹è¯•æ ·æœ¬å¯è§†åŒ–: {out_path}")


def plot_comprehensive_summary(train_data: Dict, test_data: Dict, save_dir: str):
    """ç»˜åˆ¶ç»¼åˆæ±‡æ€»å›¾"""
    fig = plt.figure(figsize=(16, 10))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    
    # 1. æŸå¤±æ›²çº¿
    ax1 = fig.add_subplot(gs[0, :2])
    history = train_data['training_history']
    epochs = [h['epoch'] for h in history]
    # æ”¯æŒæ–°æ—§æ ¼å¼
    if 'train_loss_result' in history[0]:
        train_losses = [h['train_loss_result']['total'] for h in history]
        val_losses = [h['val_loss_result']['total'] for h in history]
    else:
        train_losses = [h['train_loss'] for h in history]
        val_losses = [h['val_loss'] for h in history]
    
    ax1.plot(epochs, train_losses, color=RESEARCH_COLORS['blue'], marker='o', 
            label='Train Total Loss', markersize=3, linewidth=2.0, alpha=0.85)
    ax1.plot(epochs, val_losses, color=RESEARCH_COLORS['red'], marker='s', 
            label='Val Total Loss', markersize=3, linewidth=2.0, alpha=0.85)
    if test_data:
        test_loss = test_data.get('test_loss_result', {}).get('total', test_data.get('test_loss', None))
        if test_loss is not None:
            ax1.axhline(y=test_loss, color=RESEARCH_COLORS['green'], linestyle='--', 
                       linewidth=2, alpha=0.85, label=f"Test Loss: {test_loss:.4f}")
    ax1.set_xlabel('Epoch', fontsize=11, fontweight='bold')
    ax1.set_ylabel('Total Loss', fontsize=11, fontweight='bold')
    ax1.set_title('Training Progress: Total Loss Curves', fontsize=12, fontweight='bold')
    ax1.legend(fontsize=9, framealpha=0.9, edgecolor='black')
    ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
    ax1.spines['top'].set_visible(False)
    ax1.spines['right'].set_visible(False)
    ax1.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
    ax1.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
    
    # 2. è®­ç»ƒä¿¡æ¯æ–‡æœ¬
    ax2 = fig.add_subplot(gs[0, 2])
    ax2.axis('off')
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæŸå¤±åˆ†é‡ï¼ˆæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
    loss_info = ""
    if 'train_loss_result' in history[0]:
        first_train_losses = history[0]['train_loss_result'].get('losses', {})
        has_individual_losses = bool(first_train_losses)
        if has_individual_losses:
            # è·å–æœ€ç»ˆæŸå¤±åˆ†é‡
            final_train_losses = history[-1]['train_loss_result'].get('losses', {})
            final_val_losses = history[-1]['val_loss_result'].get('losses', {})
            loss_info = "\næŸå¤±åˆ†é‡:\n"
            for loss_name in sorted(set(list(final_train_losses.keys()) + list(final_val_losses.keys()))):
                train_val = final_train_losses.get(loss_name, 'N/A')
                val_val = final_val_losses.get(loss_name, 'N/A')
                if isinstance(train_val, (int, float)) and isinstance(val_val, (int, float)):
                    loss_info += f"â€¢ {loss_name}: T={train_val:.4f}, V={val_val:.4f}\n"
    
    info_text = f"""è®­ç»ƒä¿¡æ¯
    
æ—¶é—´æˆ³: {train_data['timestamp']}
æ€»è½®æ•°: {train_data['total_epochs']}
æœ€ä½³æ¨¡å‹: {os.path.basename(train_data['best_model_path'])}

æœ€ç»ˆæŸå¤±:
â€¢ Train: {train_losses[-1]:.6f}
â€¢ Val: {val_losses[-1]:.6f}

æœ€ä½³æŸå¤±:
â€¢ Train: {min(train_losses):.6f}
â€¢ Val: {min(val_losses):.6f}
{loss_info}
"""
    ax2.text(0.05, 0.95, info_text, transform=ax2.transAxes, 
            fontsize=10, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
    
    # 3. éªŒè¯æŒ‡æ ‡æ›²çº¿
    ax3 = fig.add_subplot(gs[1, :])
    metrics_names = ['Precision', 'Recall', 'F1', 'IoU', 'EMD', 'Score']
    colors = [RESEARCH_COLORS['blue'], RESEARCH_COLORS['green'], RESEARCH_COLORS['red'],
              RESEARCH_COLORS['purple'], RESEARCH_COLORS['orange'], RESEARCH_COLORS['light_orange']]
    
    for metric, color in zip(metrics_names, colors):
        values = [h['val_metrics'].get(metric, 0.0) for h in history]
        ax3.plot(epochs, values, color=color, marker='o', label=metric, 
                markersize=3, linewidth=2.0, alpha=0.85)
    
    ax3.set_xlabel('Epoch', fontsize=11, fontweight='bold')
    ax3.set_ylabel('Metric Value', fontsize=11, fontweight='bold')
    ax3.set_title('Validation Metrics Evolution', fontsize=12, fontweight='bold')
    ax3.legend(loc='best', fontsize=9, framealpha=0.9, edgecolor='black', ncol=3)
    ax3.grid(True, alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
    ax3.spines['top'].set_visible(False)
    ax3.spines['right'].set_visible(False)
    ax3.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
    ax3.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
    
    # 4. æµ‹è¯•æŒ‡æ ‡æŸ±çŠ¶å›¾
    if test_data:
        ax4 = fig.add_subplot(gs[2, :2])
        test_metrics = test_data['test_metrics']
        labels = ['Precision', 'Recall', 'F1', 'IoU', 'EMD', 'Score']
        values = [
            test_metrics['Precision'],
            test_metrics['Recall'],
            test_metrics['F1'],
            test_metrics['IoU'],
            test_metrics.get('EMD', 0.0),
            test_metrics['Score']
        ]
        colors_bar = [RESEARCH_COLORS['green'], RESEARCH_COLORS['orange'], RESEARCH_COLORS['red'],
                     RESEARCH_COLORS['purple'], RESEARCH_COLORS['light_orange'], RESEARCH_COLORS['blue']]
        
        x = np.arange(len(labels))
        bars = ax4.bar(x, values, color=colors_bar, alpha=0.7, edgecolor='black', linewidth=1.2,
                      hatch=[HATCH_PATTERNS[i % len(HATCH_PATTERNS)] for i in range(len(labels))])
        ax4.set_xticks(x)
        ax4.set_xticklabels(labels, fontsize=10, rotation=15, ha='right')
        ax4.set_ylabel('Value', fontsize=11, fontweight='bold')
        ax4.set_title('Test Metrics Summary', fontsize=12, fontweight='bold')
        ax4.grid(True, axis='y', alpha=0.3, linestyle='--', linewidth=0.5, color=RESEARCH_COLORS['gray'])
        ax4.spines['top'].set_visible(False)
        ax4.spines['right'].set_visible(False)
        ax4.spines['left'].set_color(RESEARCH_COLORS['dark_gray'])
        ax4.spines['bottom'].set_color(RESEARCH_COLORS['dark_gray'])
        
        for bar, val in zip(bars, values):
            ax4.text(bar.get_x() + bar.get_width()/2, val, f'{val:.3f}', 
                    ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        # 5. æµ‹è¯•ä¿¡æ¯æ–‡æœ¬
        ax5 = fig.add_subplot(gs[2, 2])
        ax5.axis('off')
        # æ”¯æŒæ–°çš„æŸå¤±æ ¼å¼
        test_loss_result = test_data.get('test_loss_result', {})
        if test_loss_result:
            test_loss = test_loss_result.get('total', test_data.get('test_loss', 0.0))
            test_losses = test_loss_result.get('losses', {})
        else:
            test_loss = test_data.get('test_loss', 0.0)
            test_losses = {}
        
        loss_info = ""
        if test_losses:
            loss_info = "\næŸå¤±åˆ†é‡:\n"
            for loss_name, loss_value in sorted(test_losses.items()):
                loss_info += f"â€¢ {loss_name}: {loss_value:.4f}\n"
        
        test_info = f"""æµ‹è¯•ç»“æœ

æµ‹è¯•æŸå¤±: {test_loss:.6f}{loss_info}

æ€§èƒ½æŒ‡æ ‡:
â€¢ Precision: {test_metrics['Precision']:.4f}
â€¢ Recall: {test_metrics['Recall']:.4f}
â€¢ F1 Score: {test_metrics['F1']:.4f}
â€¢ IoU: {test_metrics['IoU']:.4f}
â€¢ EMD: {test_metrics.get('EMD', 0.0):.4f}
â€¢ Score: {test_metrics['Score']:.4f}

æµ‹è¯•æ ·æœ¬æ•°: {test_data.get('num_samples', 'N/A')}
"""
        ax5.text(0.05, 0.95, test_info, transform=ax5.transAxes, 
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))
    
    fig.suptitle('Comprehensive Training & Testing Report', 
                fontsize=16, fontweight='bold')
    
    out_path = os.path.join(save_dir, 'comprehensive_report.png')
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜ç»¼åˆæŠ¥å‘Š: {out_path}")


def generate_all_plots(timestamp: str, result_dir: str = 'result', max_samples: int = 20):
    """
    ä»JSONæ•°æ®ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
        
        Args:
        timestamp: æ—¶é—´æˆ³ï¼Œè‡ªåŠ¨æŸ¥æ‰¾å¯¹åº”çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        result_dir: resultæ ¹ç›®å½•ï¼Œä¿å­˜ç›®å½•è‡ªåŠ¨è®¾ç½®ä¸ºresult/{timestamp}/visual/
        max_samples: æœ€å¤§æ ·æœ¬å¯è§†åŒ–æ•°é‡
    """
    print("=" * 60)
    print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("=" * 60)
    
    # ç»„è£…è·¯å¾„
    result_timestamp_dir = os.path.join(result_dir, timestamp)
    train_json = os.path.join(result_timestamp_dir, f'train_{timestamp}.json')
    test_json = os.path.join(result_timestamp_dir, f'test_{timestamp}.json')
    save_dir = os.path.join(result_timestamp_dir, 'visual')
    
    print(f"\nğŸ• ä½¿ç”¨æ—¶é—´æˆ³: {timestamp}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(train_json):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®: {train_json}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½è®­ç»ƒæ•°æ®
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®: {train_json}")
    train_data = load_train_data(train_json)
    
    # åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    test_data = None
    if os.path.exists(test_json):
        print(f"ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®: {test_json}")
        test_data = load_test_data(test_json)
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®: {test_json}ï¼Œä»…ä½¿ç”¨è®­ç»ƒæ•°æ®ç”Ÿæˆå¯è§†åŒ–")
    
    print(f"\nğŸ’¾ ä¿å­˜ç›®å½•: {save_dir}\n")
    
    # ç”Ÿæˆå„ç§å›¾è¡¨
    plot_loss_curves(train_data, save_dir)
    plot_val_metrics_curves(train_data, save_dir)
    
    if test_data:
        plot_test_metrics_summary(test_data, save_dir)
        plot_random_test_samples(test_data, save_dir, max_samples)
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“ ä¿å­˜ç›®å½•: {save_dir}")
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser('Generate visualizations from JSON data')
    parser.add_argument('--timestamp', type=str, required=True, help='Model timestamp (e.g., 20251023_123456). Auto-find train and test JSON files from result/{timestamp}/')
    parser.add_argument('--result_dir', type=str, default='result', help='Root directory containing experiment results (save dir auto-set to result/{timestamp}/visual/)')
    parser.add_argument('--max_samples', type=int, default=20, help='Maximum number of test samples to visualize')
    
    args = parser.parse_args()
    
    generate_all_plots(args.timestamp, args.result_dir, args.max_samples)


if __name__ == '__main__':
    main()
